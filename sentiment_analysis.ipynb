{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import openai\n",
    "from openai.error import RateLimitError\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pprint import pprint\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import krippendorff\n",
    "from sklearn.metrics import classification_report\n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Mein OpenAI API Token ist in der .env Datei abgespeichert. Mit folgenden Funktionen lade ich den Token, ohne diesen direkt in diesem Notebook hinterlegen zu müssen.\n",
    "environment_variables = dotenv_values()\n",
    "openai.api_key = environment_variables[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotierte Reddit Kommentare\n",
    "\n",
    "Meine fertig annotierten Reddit Kommentare lade ich mit der Polars Bibliothek aus einer CSV Datei in ein Polars Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_000, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>comment_id</th><th>subreddit</th><th>title</th><th>body</th><th>created_utc</th><th>comment_url</th><th>annotation</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>datetime[μs]</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>28118968601</td><td>&quot;de&quot;</td><td>&quot;Dilemma&quot;</td><td>&quot;Das ist ja gen…</td><td>2015-11-15 21:21:53</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>28219776121</td><td>&quot;de&quot;</td><td>&quot;15 bekannte Ze…</td><td>&quot;&quot;Die Flüchtlin…</td><td>2016-01-07 14:26:51</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>28215376812</td><td>&quot;de&quot;</td><td>&quot;Rechtsextreme …</td><td>&quot;wobei man darü…</td><td>2016-01-05 12:55:49</td><td>&quot;https://www.re…</td><td>&quot;a&quot;</td></tr><tr><td>28215451441</td><td>&quot;de&quot;</td><td>&quot;Rechtsextreme …</td><td>&quot;Ich streite ni…</td><td>2016-01-05 14:03:53</td><td>&quot;https://www.re…</td><td>&quot;s&quot;</td></tr><tr><td>28306497360</td><td>&quot;de&quot;</td><td>&quot;Länder des Wes…</td><td>&quot;Die Situation …</td><td>2016-02-18 20:32:35</td><td>&quot;https://www.re…</td><td>&quot;s&quot;</td></tr><tr><td>28201508909</td><td>&quot;de&quot;</td><td>&quot;Gemüse und Gem…</td><td>&quot;Warum müssen e…</td><td>2015-12-29 01:39:25</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>28118443956</td><td>&quot;de&quot;</td><td>&quot;Langsam sind a…</td><td>&quot;Jap. Zumal auf…</td><td>2015-11-15 16:13:22</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>27978086489</td><td>&quot;de&quot;</td><td>&quot;Eure Prognose …</td><td>&quot;[Bosnienkrieg …</td><td>2015-09-03 17:01:48</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>28141803287</td><td>&quot;de&quot;</td><td>&quot;Dresdnerin hat…</td><td>&quot;wo steht eigen…</td><td>2015-11-27 18:18:43</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>28295900263</td><td>&quot;de&quot;</td><td>&quot;CSU: Mehr Flüc…</td><td>&quot;Gratuliere, da…</td><td>2016-02-13 18:02:56</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>27997590898</td><td>&quot;de&quot;</td><td>&quot;Sigmar Gabriel…</td><td>&quot;Gibt es Prezen…</td><td>2015-09-14 11:55:37</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>28219579902</td><td>&quot;de&quot;</td><td>&quot;Köln: Das steh…</td><td>&quot;Weil sie sich …</td><td>2016-01-07 11:10:49</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>39124746764</td><td>&quot;de&quot;</td><td>&quot;Rassismus in d…</td><td>&quot;Flüchtlinge si…</td><td>2022-03-02 14:21:00</td><td>&quot;https://www.re…</td><td>&quot;s&quot;</td></tr><tr><td>39132784598</td><td>&quot;de&quot;</td><td>&quot;KW 09 / 22 (Do…</td><td>&quot;Dieser Bürgere…</td><td>2022-03-03 14:14:22</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>38904149316</td><td>&quot;de&quot;</td><td>&quot;&quot;Immigration i…</td><td>&quot;Worauf vorbere…</td><td>2022-02-03 10:20:55</td><td>&quot;https://www.re…</td><td>&quot;s&quot;</td></tr><tr><td>39202692348</td><td>&quot;de&quot;</td><td>&quot;Agrarminister …</td><td>&quot;Klar ist sie d…</td><td>2022-03-12 06:15:56</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>40319939717</td><td>&quot;de&quot;</td><td>&quot;Ich bin Asylen…</td><td>&quot;Hm, die Vertei…</td><td>2022-08-03 18:56:52</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>39044375499</td><td>&quot;de&quot;</td><td>&quot;Ukraine - Russ…</td><td>&quot;Das klingt nat…</td><td>2022-02-20 16:59:17</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>40356247365</td><td>&quot;de&quot;</td><td>&quot;Montagmorgen –…</td><td>&quot;Alle Programme…</td><td>2022-08-08 08:40:10</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>40422722063</td><td>&quot;de&quot;</td><td>&quot;Scholz verteid…</td><td>&quot;Russen die in …</td><td>2022-08-16 13:38:25</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>40189576332</td><td>&quot;de&quot;</td><td>&quot;&quot;WiR kÖnNeN uN…</td><td>&quot;Man muss beden…</td><td>2022-07-18 16:44:39</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>40155562339</td><td>&quot;de&quot;</td><td>&quot;Das schlimmste…</td><td>&quot;Die realisiere…</td><td>2022-07-14 07:15:02</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>39642165105</td><td>&quot;de&quot;</td><td>&quot;Statement von …</td><td>&quot;Ist ja nicht v…</td><td>2022-05-06 22:20:27</td><td>&quot;https://www.re…</td><td>&quot;na&quot;</td></tr><tr><td>39904950343</td><td>&quot;de&quot;</td><td>&quot;Oberstes Geric…</td><td>&quot;Rein mathemati…</td><td>2022-06-11 08:34:15</td><td>&quot;https://www.re…</td><td>&quot;s&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_000, 7)\n",
       "┌─────────────┬───────────┬──────────────┬──────────────┬──────────────┬──────────────┬────────────┐\n",
       "│ comment_id  ┆ subreddit ┆ title        ┆ body         ┆ created_utc  ┆ comment_url  ┆ annotation │\n",
       "│ ---         ┆ ---       ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---        │\n",
       "│ i64         ┆ str       ┆ str          ┆ str          ┆ datetime[μs] ┆ str          ┆ str        │\n",
       "╞═════════════╪═══════════╪══════════════╪══════════════╪══════════════╪══════════════╪════════════╡\n",
       "│ 28118968601 ┆ de        ┆ Dilemma      ┆ Das ist ja   ┆ 2015-11-15   ┆ https://www. ┆ na         │\n",
       "│             ┆           ┆              ┆ genau mein   ┆ 21:21:53     ┆ reddit.com/r ┆            │\n",
       "│             ┆           ┆              ┆ Punkt: *je…  ┆              ┆ /de/comm…    ┆            │\n",
       "│ 28219776121 ┆ de        ┆ 15 bekannte  ┆ \"Die         ┆ 2016-01-07   ┆ https://www. ┆ na         │\n",
       "│             ┆           ┆ Zeichner     ┆ Flüchtlinge  ┆ 14:26:51     ┆ reddit.com/r ┆            │\n",
       "│             ┆           ┆ haben sich … ┆ sind alle    ┆              ┆ /de/comm…    ┆            │\n",
       "│             ┆           ┆              ┆ krimi…       ┆              ┆              ┆            │\n",
       "│ 28215376812 ┆ de        ┆ Rechtsextrem ┆ wobei man    ┆ 2016-01-05   ┆ https://www. ┆ a          │\n",
       "│             ┆           ┆ e nutzen     ┆ darüber      ┆ 12:55:49     ┆ reddit.com/r ┆            │\n",
       "│             ┆           ┆ Köln für ra… ┆ nicht        ┆              ┆ /de/comm…    ┆            │\n",
       "│             ┆           ┆              ┆ vergesse…    ┆              ┆              ┆            │\n",
       "│ 28215451441 ┆ de        ┆ Rechtsextrem ┆ Ich streite  ┆ 2016-01-05   ┆ https://www. ┆ s          │\n",
       "│             ┆           ┆ e nutzen     ┆ nicht ab,    ┆ 14:03:53     ┆ reddit.com/r ┆            │\n",
       "│             ┆           ┆ Köln für ra… ┆ dass die V…  ┆              ┆ /de/comm…    ┆            │\n",
       "│ …           ┆ …         ┆ …            ┆ …            ┆ …            ┆ …            ┆ …          │\n",
       "│ 40189576332 ┆ de        ┆ \"WiR kÖnNeN  ┆ Man muss     ┆ 2022-07-18   ┆ https://www. ┆ na         │\n",
       "│             ┆           ┆ uNd WeRdEn   ┆ bedenken,    ┆ 16:44:39     ┆ reddit.com/r ┆            │\n",
       "│             ┆           ┆ IhNeN hEl…   ┆ dass die     ┆              ┆ /de/comm…    ┆            │\n",
       "│             ┆           ┆              ┆ Behö…        ┆              ┆              ┆            │\n",
       "│ 40155562339 ┆ de        ┆ Das          ┆ Die          ┆ 2022-07-14   ┆ https://www. ┆ na         │\n",
       "│             ┆           ┆ schlimmste   ┆ realisieren  ┆ 07:15:02     ┆ reddit.com/r ┆            │\n",
       "│             ┆           ┆ aller        ┆ das, wenn    ┆              ┆ /de/comm…    ┆            │\n",
       "│             ┆           ┆ Unwetter: H… ┆ sie si…      ┆              ┆              ┆            │\n",
       "│ 39642165105 ┆ de        ┆ Statement    ┆ Ist ja nicht ┆ 2022-05-06   ┆ https://www. ┆ na         │\n",
       "│             ┆           ┆ von Fynn     ┆ verkauft     ┆ 22:20:27     ┆ reddit.com/r ┆            │\n",
       "│             ┆           ┆ Kliemann zu  ┆ sondern ge…  ┆              ┆ /de/comm…    ┆            │\n",
       "│             ┆           ┆ d…           ┆              ┆              ┆              ┆            │\n",
       "│ 39904950343 ┆ de        ┆ Oberstes     ┆ Rein         ┆ 2022-06-11   ┆ https://www. ┆ s          │\n",
       "│             ┆           ┆ Gericht      ┆ mathematisch ┆ 08:34:15     ┆ reddit.com/r ┆            │\n",
       "│             ┆           ┆ weist Klage  ┆ gesehen      ┆              ┆ /de/comm…    ┆            │\n",
       "│             ┆           ┆ ab:…         ┆ könnte…      ┆              ┆              ┆            │\n",
       "└─────────────┴───────────┴──────────────┴──────────────┴──────────────┴──────────────┴────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_comments_df = pl.read_csv(\"datasets/annotated_comments_final.csv\")\n",
    "\n",
    "# Die Spalte mit dem Timestamp \"created_utc\" muss ich einmalig von einem String in einen richtigen Timestamp umwandeln.\n",
    "annotated_comments_df = annotated_comments_df.with_columns(pl.col(\"created_utc\").str.strptime(dtype=pl.Datetime))\n",
    "\n",
    "annotated_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen\n",
    "\n",
    "Für die weitere Annotation der Kommentare mit der OpenAI API habe ich folgende Hilfsfunktionen programmiert, welche anschließend für jeden Prompt in einer großen Funktion ausgeführt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dateneinlesen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Einlesen der Annotationsergebnisse zu testen, erstelle ich an dieser Stelle einmalig ein Beispiel-Dataset und schreibe es als Parquet Datei an den angegebnen Pfad. Die folgenden Funktionen kann ich dann mit diesem Beispiel-Dataset testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel-Kommentardatenset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>comment_id</th><th>comment_text</th></tr><tr><td>i64</td><td>str</td></tr></thead><tbody><tr><td>1001</td><td>&quot;Comment 1001&quot;</td></tr><tr><td>1002</td><td>&quot;Comment 1002&quot;</td></tr><tr><td>1002</td><td>&quot;Comment 1003&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────────┬──────────────┐\n",
       "│ comment_id ┆ comment_text │\n",
       "│ ---        ┆ ---          │\n",
       "│ i64        ┆ str          │\n",
       "╞════════════╪══════════════╡\n",
       "│ 1001       ┆ Comment 1001 │\n",
       "│ 1002       ┆ Comment 1002 │\n",
       "│ 1002       ┆ Comment 1003 │\n",
       "└────────────┴──────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pfad an welchem das Dataset gespeichert wird\n",
    "example_comments_parquet_path = \"datasets/example_comments.parquet\"\n",
    "\n",
    "# Beispieldaten\n",
    "data = [[1001, \"Comment 1001\"], [1002, \"Comment 1002\"], [1002, \"Comment 1003\"]]\n",
    "\n",
    "# Mit dem Beispieldaten erstelle ich ein Polars Dataframe\n",
    "example_comments_df = pl.DataFrame(schema=[\"comment_id\", \"comment_text\"], data=data)\n",
    "\n",
    "# und speiche das Dataframe an den Pfad als Parquet Datei ab.\n",
    "example_comments_df.write_parquet(example_comments_parquet_path)\n",
    "\n",
    "print(\"Beispiel-Kommentardatenset: \")\n",
    "example_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn ich eine Prompt-Evaluation abbreche, möchte ich bei dem Start des nächsten Durchlauf die Kommentare für welche ich bereits Annotation bekommen habe nicht nochmals annotieren lassen. Deshalb habe ich folgende Funktion programmiert, um die comment_ids für gegebenenfalls bereits vorhandene Annotationsergenisse zu erhalten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folge comment_ids wurden an dem angegebenen Pfad gefunden:  [1001, 1002, 1002]\n"
     ]
    }
   ],
   "source": [
    "def get_comment_ids_of_previous_annotations(parquet_path):\n",
    "    # An dem Pfad parquet_path befinden sich eventuell noch keine Ergenisse. Zum Beispiel beim aller ersten Durchlauf einer\n",
    "    # Prompt-Evaluation. Deshalb muss ich das Einlesen des Dataset in eine Try Except Block setzen. Befindet sich an dem\n",
    "    # angegebenen Pfad keine Datei gebe ich deshalb eine leere Liste mit keinen comment_ids zurück.\n",
    "    try:\n",
    "        prev_comment_ids = pl.read_parquet(parquet_path).select(\"comment_id\").to_series().to_list()\n",
    "        return prev_comment_ids\n",
    "    except FileNotFoundError:\n",
    "        return []\n",
    "\n",
    "\n",
    "prev_annotated_comment_ids = get_comment_ids_of_previous_annotations(example_comments_parquet_path)\n",
    "\n",
    "print(\"Folge comment_ids wurden an dem angegebenen Pfad gefunden: \", prev_annotated_comment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei jedem Prompt-Evaluation Durchlauf möchte ich die Ergenisse an den angegebenen Pfad als Parquet Datei abspeichern. Bereits vorhandene Ergenisse sollen dabei aber nicht überschrieben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel-Dataset mit neuen Kommentaren: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>comment_id</th><th>comment_text</th></tr><tr><td>i64</td><td>str</td></tr></thead><tbody><tr><td>1001</td><td>&quot;Comment 1001&quot;</td></tr><tr><td>1002</td><td>&quot;Comment 1002&quot;</td></tr><tr><td>1002</td><td>&quot;Comment 1003&quot;</td></tr><tr><td>1004</td><td>&quot;Comment 1004&quot;</td></tr><tr><td>1005</td><td>&quot;Comment 1005&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────┬──────────────┐\n",
       "│ comment_id ┆ comment_text │\n",
       "│ ---        ┆ ---          │\n",
       "│ i64        ┆ str          │\n",
       "╞════════════╪══════════════╡\n",
       "│ 1001       ┆ Comment 1001 │\n",
       "│ 1002       ┆ Comment 1002 │\n",
       "│ 1002       ┆ Comment 1003 │\n",
       "│ 1004       ┆ Comment 1004 │\n",
       "│ 1005       ┆ Comment 1005 │\n",
       "└────────────┴──────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_annotations_to_comment_dataset(parquet_path, df):\n",
    "    # An dem angegebenen Pfad befinden sich eventuel bereits Ergenisse.\n",
    "    try:\n",
    "        # Wenn das der Fall ist, lese ich die bereits vorhandenen Ergenisse ein und hänge die neuen Daten an.\n",
    "        prev_annotated_comments_df = pl.read_parquet(parquet_path)\n",
    "        updated_annotated_comments_df = prev_annotated_comments_df.vstack(df)\n",
    "        updated_annotated_comments_df.write_parquet(parquet_path)\n",
    "    except FileNotFoundError:\n",
    "        # Wenn noch keine vorherigen Ergebnisse vorhanden sind, schreibe ich einfach direkt die neuen Daten an\n",
    "        # den angegebenen Pfad.\n",
    "        df.write_parquet(parquet_path)\n",
    "\n",
    "\n",
    "# Hier erstelle ich ein Polars Dataframe mit neuen Kommentaren, welche den bereits vorhandenen Kommentaren angehangen werden sollen.\n",
    "new_comments = [[1004, \"Comment 1004\"], [1005, \"Comment 1005\"]]\n",
    "new_comments_df = pl.DataFrame(schema=[\"comment_id\", \"comment_text\"], data=new_comments)\n",
    "\n",
    "write_annotations_to_comment_dataset(example_comments_parquet_path, new_comments_df)\n",
    "\n",
    "print(\"Beispiel-Dataset mit neuen Kommentaren: \")\n",
    "updated_dataset = pl.read_parquet(example_comments_parquet_path)\n",
    "updated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den folgenden Hilfsfunktionen kann ich jede Art von Prompt generieren, zum Beispiel Zero Shot oder Few Shot Prompts. Die OpenAI API benötigt für das Model \"gpt-3.5-turbo\" eine Liste von Dicts. Diese Python Dicts enhalten die \"role\" (z.B. \"system\" für den Systemprompt oder \"user\" für den Userprompt) und den eigentlichen Text des Prompt im Feld \"content\" des Dict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel Zero Shot Prompt Messages: \n",
      "[{'role': 'system', 'content': 'Dies ist der System Prompt.'}, {'role': 'user', 'content': 'Beispieltext'}]\n"
     ]
    }
   ],
   "source": [
    "def zero_shot_prompt_messages(system_prompt, comment_text):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": comment_text},\n",
    "    ]\n",
    "\n",
    "\n",
    "system_prompt = \"Dies ist der System Prompt.\"\n",
    "comment_text = \"Beispieltext\"\n",
    "prompt_messages = zero_shot_prompt_messages(system_prompt, comment_text)\n",
    "\n",
    "print(\"Beispiel Zero Shot Prompt Messages: \")\n",
    "print(prompt_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel Few Shot Prompt Messages: \n",
      "[{'content': 'Dies ist der System Prompt.', 'role': 'system'},\n",
      " {'content': 'Beispiel 01', 'role': 'user'},\n",
      " {'content': 'Nicht-Zutreffend', 'role': 'assistant'},\n",
      " {'content': 'Beispiel 02', 'role': 'user'},\n",
      " {'content': 'Anti-Solidarität', 'role': 'assistant'},\n",
      " {'content': 'Beispiel 03', 'role': 'user'},\n",
      " {'content': 'Solidarität', 'role': 'assistant'},\n",
      " {'content': 'Beispieltext', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "def few_shot_prompt_messages(system_prompt, comment_text, few_shot_examples):\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    for user_prompt, assistent_prompt in few_shot_examples:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistent_prompt})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": comment_text})\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "few_shot_examples = [\n",
    "    (\"Beispiel 01\", \"Nicht-Zutreffend\"),\n",
    "    (\"Beispiel 02\", \"Anti-Solidarität\"),\n",
    "    (\"Beispiel 03\", \"Solidarität\"),\n",
    "]\n",
    "\n",
    "prompt_messages = few_shot_prompt_messages(system_prompt, comment_text, few_shot_examples)\n",
    "\n",
    "print(\"Beispiel Few Shot Prompt Messages: \")\n",
    "\n",
    "# Hier nutze ich \"Pretty Print\", um die Liste der Dicts übersichtlich darzustellen.\n",
    "# vgl. https://realpython.com/python-pretty-print/\n",
    "pprint(prompt_messages, width=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel Chain of Thought Prompt Messages: \n",
      "[{'content': 'Dies ist der System Prompt.', 'role': 'system'},\n",
      " {'content': 'Beispieltext', 'role': 'user'},\n",
      " {'content': 'Ich denke folgendes...', 'role': 'assistant'},\n",
      " {'content': 'Wähle jetzt eine der folgenden Optionen: Option 1, Option 2, Option 3', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "def cot_prompt_messages(system_prompt, comment_text, model_tought, annotation_prompt):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": comment_text},\n",
    "        {\"role\": \"assistant\", \"content\": model_tought},\n",
    "        {\"role\": \"user\", \"content\": annotation_prompt},\n",
    "    ]\n",
    "\n",
    "\n",
    "model_tought = \"Ich denke folgendes...\"\n",
    "annotation_prompt = \"Wähle jetzt eine der folgenden Optionen: Option 1, Option 2, Option 3\"\n",
    "prompt_messages = cot_prompt_messages(system_prompt, comment_text, model_tought, annotation_prompt)\n",
    "\n",
    "print(\"Beispiel Chain of Thought Prompt Messages: \")\n",
    "\n",
    "# Hier nutze ich \"Pretty Print\", um die Liste der Dicts übersichtlich darzustellen.\n",
    "# vgl. https://realpython.com/python-pretty-print/\n",
    "pprint(prompt_messages, width=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel Chain of Thought Prompt Messages um den Thought zu generieren: \n",
      "[{'content': 'Dies ist der System Prompt.', 'role': 'system'},\n",
      " {'content': 'Beispiel Kommentar 01', 'role': 'user'},\n",
      " {'content': 'Gedanke 01', 'role': 'assistant'},\n",
      " {'content': 'Wähle jetzt eine der folgenden Optionen: Option 1, Option 2, Option 3', 'role': 'user'},\n",
      " {'content': 'Finale Annotation 01', 'role': 'assistant'},\n",
      " {'content': 'Beispiel Kommentar 02', 'role': 'user'},\n",
      " {'content': 'Gedanke 02', 'role': 'assistant'},\n",
      " {'content': 'Wähle jetzt eine der folgenden Optionen: Option 1, Option 2, Option 3', 'role': 'user'},\n",
      " {'content': 'Finale Annotation 02', 'role': 'assistant'},\n",
      " {'content': 'Beispiel Kommentar 03', 'role': 'user'},\n",
      " {'content': 'Gedanke 03', 'role': 'assistant'},\n",
      " {'content': 'Wähle jetzt eine der folgenden Optionen: Option 1, Option 2, Option 3', 'role': 'user'},\n",
      " {'content': 'Finale Annotation 03', 'role': 'assistant'},\n",
      " {'content': 'Beispiel Kommentar 04', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "def cot_few_shot_THOUGHT_prompt_messages(system_prompt, cot_few_shot_examples, annotation_prompt, comment_text):\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    for example in cot_few_shot_examples:\n",
    "        messages.append({\"role\": \"user\", \"content\": example[\"user\"]})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": example[\"assistant\"]})\n",
    "        messages.append({\"role\": \"user\", \"content\": annotation_prompt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": example[\"annotation\"]})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": comment_text})\n",
    "    return messages\n",
    "\n",
    "\n",
    "system_prompt = \"Dies ist der System Prompt.\"\n",
    "\n",
    "cot_few_shot_examples = [\n",
    "    {\"user\": \"Beispiel Kommentar 01\", \"assistant\": \"Gedanke 01\", \"annotation\": \"Finale Annotation 01\"},\n",
    "    {\"user\": \"Beispiel Kommentar 02\", \"assistant\": \"Gedanke 02\", \"annotation\": \"Finale Annotation 02\"},\n",
    "    {\"user\": \"Beispiel Kommentar 03\", \"assistant\": \"Gedanke 03\", \"annotation\": \"Finale Annotation 03\"},\n",
    "]\n",
    "\n",
    "annotation_prompt = \"Wähle jetzt eine der folgenden Optionen: Option 1, Option 2, Option 3\"\n",
    "comment_text = \"Beispiel Kommentar 04\"\n",
    "\n",
    "prompt_messages = cot_few_shot_THOUGHT_prompt_messages(system_prompt, cot_few_shot_examples, annotation_prompt, comment_text)\n",
    "\n",
    "print(\"Beispiel Chain of Thought Prompt Messages um den Thought zu generieren: \")\n",
    "\n",
    "# Hier nutze ich \"Pretty Print\", um die Liste der Dicts übersichtlich darzustellen.\n",
    "# vgl. https://realpython.com/python-pretty-print/\n",
    "pprint(prompt_messages, width=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel Chain of Thought Prompt Messages um die finale Annotation zu generieren: \n",
      "[{'content': 'Dies ist der System Prompt.', 'role': 'system'},\n",
      " {'content': 'Beispiel Kommentar 01', 'role': 'user'},\n",
      " {'content': 'Gedanke 01', 'role': 'assistant'},\n",
      " {'content': 'Wähle jetzt eine der folgenden Optionen: Option 1, Option 2, Option 3', 'role': 'user'},\n",
      " {'content': 'Finale Annotation 01', 'role': 'assistant'},\n",
      " {'content': 'Beispiel Kommentar 02', 'role': 'user'},\n",
      " {'content': 'Gedanke 02', 'role': 'assistant'},\n",
      " {'content': 'Wähle jetzt eine der folgenden Optionen: Option 1, Option 2, Option 3', 'role': 'user'},\n",
      " {'content': 'Finale Annotation 02', 'role': 'assistant'},\n",
      " {'content': 'Beispiel Kommentar 03', 'role': 'user'},\n",
      " {'content': 'Gedanke 03', 'role': 'assistant'},\n",
      " {'content': 'Wähle jetzt eine der folgenden Optionen: Option 1, Option 2, Option 3', 'role': 'user'},\n",
      " {'content': 'Finale Annotation 03', 'role': 'assistant'},\n",
      " {'content': 'Beispiel Kommentar 04', 'role': 'user'},\n",
      " {'content': 'Ich denke...', 'role': 'assistant'},\n",
      " {'content': 'Wähle jetzt eine der folgenden Optionen: Option 1, Option 2, Option 3', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "def cot_few_shot_FINAL_ANNOTATION_prompt_messages(prev_cot_messages, model_thought, annotation_prompt):\n",
    "    prev_cot_messages.append({\"role\": \"assistant\", \"content\": model_thought})\n",
    "    prev_cot_messages.append({\"role\": \"user\", \"content\": annotation_prompt})\n",
    "\n",
    "    return prev_cot_messages\n",
    "\n",
    "\n",
    "prev_cot_messages = cot_few_shot_THOUGHT_prompt_messages(system_prompt, cot_few_shot_examples, annotation_prompt, comment_text)\n",
    "model_thought = \"Ich denke...\"\n",
    "\n",
    "prompt_messages = cot_few_shot_FINAL_ANNOTATION_prompt_messages(prev_cot_messages, model_thought, annotation_prompt)\n",
    "\n",
    "print(\"Beispiel Chain of Thought Prompt Messages um die finale Annotation zu generieren: \")\n",
    "\n",
    "# Hier nutze ich \"Pretty Print\", um die Liste der Dicts übersichtlich darzustellen.\n",
    "# vgl. https://realpython.com/python-pretty-print/\n",
    "pprint(prompt_messages, width=140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Anfragen an die OpenAI API zu senden, nutze ich die offizielle OpenAI Python Bibliothek. Ich habe mir folgende Hilfsfunktion programmiert, weil die OpenAI API leider öfter Fehler ausgibt. Bei einem RateLimit Fehler warte ich deshalb für 60 Sekunden und machen danach noch einen Versuch. Bei allen anderen Fehlern warte ich nur 1 Sekunde vor dem nächsten Versuch. Dies mache ich für maximal 20 Versuche pro Anfrage.\n",
    "\n",
    "vgl. https://callmefred.com/how-to-fix-openai-error-ratelimiterror-the-server-had-an-error/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"request_timeout\" => Braucht die OpenAI API länger als 5 Sekunden, breche ich die Anfrage selber ab, weil\n",
    "# nach 5 Sekunden die Chance hoch ist, dass die Anfrage sowieso nicht beantwortet wird.\n",
    "def request_chat_completion(prompt_messages, max_token=30, temperature=0.2, request_timeout=5):\n",
    "    # Die maximale Anzahl an Versuchen, um eine Antwort von den OpenAI API zu bekommen.\n",
    "    max_retries = 20\n",
    "\n",
    "    # Die bisher durchgeführten Versuche.\n",
    "    num_retries = 0\n",
    "\n",
    "    # Dies ist eine Endlosschleife, welche solange Anfragen an die OpenAI API sendet, bis ich eine Antwort\n",
    "    # bekomme, oder die maximale Anzahl an Versuchen (20) überschritten wurde.\n",
    "    while True:\n",
    "        # Hier sende ich eine Anfrage an die OpenAI API mit der offiziellen OpenAI Python Bibliothek.\n",
    "        try:\n",
    "            return openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=prompt_messages,\n",
    "                max_tokens=max_token,\n",
    "                temperature=temperature,\n",
    "                request_timeout=request_timeout,\n",
    "            )\n",
    "\n",
    "        # Sollte ich das RateLimit überschritten haben, warte ich für 1 Minute (60 Sekunden), damit das RateLimit\n",
    "        # zurück gesetzt wird.\n",
    "        except RateLimitError as rate_limit_error:\n",
    "            print(f\"[OPENAI] RateLimit erreicht. Warte für 60 Sekunden vor dem nächsten Versuch. Bisherige Versuche: {num_retries}\")\n",
    "\n",
    "            num_retries = num_retries + 1\n",
    "\n",
    "            # Wenn die maximale Anzahl an Versuchen überschritten ist, werfe ich eine Exception um die\n",
    "            # Prompt-Evaluation-Pipeline abzubrechen.\n",
    "            if num_retries > max_retries:\n",
    "                raise Exception(f\"[OPENAI] Maximale Anzahl an Versuchen überschritten!\")\n",
    "\n",
    "            time.sleep(60)\n",
    "\n",
    "        # Bei jeder anderen Art von Fehler warte ich nur eine Sekunde und propiere es dann nochmal.\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"[OPENAI] Ein Fehler ist in der OpenAI API eingetreten. Warte für 1 Sekunden vor dem nächsten Versuch. Bisherige Versuche: {num_retries}\"\n",
    "            )\n",
    "\n",
    "            num_retries = num_retries + 1\n",
    "\n",
    "            # Wenn die maximale Anzahl an Versuchen überschritten ist, werfe ich eine Exception um die\n",
    "            # Prompt-Evaluation-Pipeline abzubrechen.\n",
    "            if num_retries > max_retries:\n",
    "                raise Exception(f\"[OPENAI] Maximum number of retries ({max_retries}) exceeded. Aborting request.\")\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "system_prompt = \"Du bist ein hilfreicher Assisten.\"\n",
    "user_prompt = \"Was ist 2+2?\"\n",
    "prompt_messages = zero_shot_prompt_messages(system_prompt, user_prompt)\n",
    "\n",
    "# openai_reponse = request_chat_completion(prompt_messages)\n",
    "\n",
    "# print(\"OpenAI API Antwort: \")\n",
    "\n",
    "# pprint(openai_reponse, width=140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Evaluation\n",
    "\n",
    "Die Hilfsfunktion \"prompt_evaluation_run\" vereint die anderen Hilfsfunktionen, um in einem Durchlauf für alle Kommentare anhand eines Prompt Annotationen zu generieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_evaluation_run(\n",
    "    annotated_comments_df,\n",
    "    prompt_type,\n",
    "    eval_results_parquet_path,\n",
    "    system_prompt,\n",
    "    max_token=30,\n",
    "    few_shot_examples=[],\n",
    "    cot_annotation_prompt=\"\",\n",
    "):\n",
    "    results = []\n",
    "    total_tokens_used = 0\n",
    "\n",
    "    # Hier hole ich mir die \"comment_ids\" aller bisher annotierter Kommentare.\n",
    "    prev_annotated_comment_ids = get_comment_ids_of_previous_annotations(eval_results_parquet_path)\n",
    "\n",
    "    # Um die Annotationen zu erstellen, brauche ich nur die Spalten \"comment_id\" und \"body\" (Kommentartext).\n",
    "    selected_comments_df = annotated_comments_df.select([\"comment_id\", \"body\"])\n",
    "\n",
    "    # Dann führe ich einen Filter aus, damit nur noch für noch nicht annotierte Kommentare Annotationen erstellt werden.\n",
    "    selected_comments = selected_comments_df.filter(~pl.col(\"comment_id\").is_in(prev_annotated_comment_ids)).to_dicts()\n",
    "\n",
    "    # Anzahl der noch nicht annotierten Kommentare.\n",
    "    num_comments = len(selected_comments)\n",
    "\n",
    "    if num_comments > 0:\n",
    "        print(f\"[PROMPT EVAL RUN] Noch {num_comments} nicht annotierte Kommentare verbleibend.\")\n",
    "    else:\n",
    "        print(f\"[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\")\n",
    "        # Wenn bereits für alle Kommentare annotation erstellt wurden, gebe ich einfach die\n",
    "        # bisheringen Ergebnisse zurück.\n",
    "        return pl.read_parquet(eval_results_parquet_path)\n",
    "\n",
    "    try:\n",
    "        # Hier interiere ich über jeden noch nicht annotierten Kommentar und lasse mir gleichzeit eine \"Progress Bar\" anzeigen.\n",
    "        for comment in tqdm(selected_comments, desc=\"Annotating comments\"):\n",
    "            # Aus dem Kommentar Dict hole ich mir den Kommentartext als String\n",
    "            comment_text = comment[\"body\"]\n",
    "\n",
    "            if prompt_type == \"ZERO_SHOT\":\n",
    "                messages = zero_shot_prompt_messages(\n",
    "                    system_prompt=system_prompt,\n",
    "                    comment_text=comment_text,\n",
    "                )\n",
    "\n",
    "            elif prompt_type == \"FEW_SHOT\":\n",
    "                messages = few_shot_prompt_messages(\n",
    "                    system_prompt=system_prompt,\n",
    "                    comment_text=comment_text,\n",
    "                    few_shot_examples=few_shot_examples,\n",
    "                )\n",
    "\n",
    "            elif prompt_type == \"CHAIN_OF_THOUGHT\":\n",
    "                # Für einen Chain of Thought Prompt muss ich im ersten Schritt zuerst einen \"Thought\" generieren.\n",
    "                cot_thought_messages = zero_shot_prompt_messages(system_prompt, comment_text)\n",
    "\n",
    "                # Der \"Thought\" darf auch länger sein. Bis zu 300 Token.\n",
    "                model_thought_max_token = 300\n",
    "\n",
    "                # Hier generiere ich den \"Thought\".\n",
    "                thought_response = request_chat_completion(\n",
    "                    prompt_messages=cot_thought_messages, max_token=model_thought_max_token, request_timeout=45\n",
    "                )\n",
    "\n",
    "                # Die für die OpenAI Anfrage benötigten Token zähle ich mit.\n",
    "                total_tokens_used = total_tokens_used + thought_response[\"usage\"][\"total_tokens\"]\n",
    "\n",
    "                # Aus der Antwort hole ich mir den \"Thought\" as String\n",
    "                model_thought = thought_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "                # und speichere den \"Thought\" im aktuellen Kommentar Dict ab.\n",
    "                comment[\"openai_thought\"] = model_thought\n",
    "\n",
    "                # Mit dem \"Thought\" kann ich jetzt die Prompt Messages für die finale Annotation erstellen.\n",
    "                messages = cot_prompt_messages(\n",
    "                    system_prompt=system_prompt,\n",
    "                    comment_text=comment_text,\n",
    "                    model_tought=model_thought,\n",
    "                    annotation_prompt=cot_annotation_prompt,\n",
    "                )\n",
    "\n",
    "            elif prompt_type == \"FEW_SHOT_CHAIN_OF_THOUGHT\":\n",
    "                # Für einen Few Shot Chain of Thought Prompt muss ich im ersten Schritt zuerst einen \"Thought\" generieren.\n",
    "                few_shot_cot_thought_messages = cot_few_shot_THOUGHT_prompt_messages(\n",
    "                    system_prompt=system_prompt,\n",
    "                    cot_few_shot_examples=few_shot_examples,\n",
    "                    annotation_prompt=cot_annotation_prompt,\n",
    "                    comment_text=comment_text,\n",
    "                )\n",
    "\n",
    "                # Der \"Thought\" darf auch länger sein. Bis zu 300 Token.\n",
    "                model_thought_max_token = 300\n",
    "\n",
    "                # Hier generiere ich den \"Thought\".\n",
    "                thought_response = request_chat_completion(\n",
    "                    prompt_messages=few_shot_cot_thought_messages, max_token=model_thought_max_token, request_timeout=45\n",
    "                )\n",
    "\n",
    "                # Die für die OpenAI Anfrage benötigten Token zähle ich mit.\n",
    "                total_tokens_used = total_tokens_used + thought_response[\"usage\"][\"total_tokens\"]\n",
    "\n",
    "                # Aus der Antwort hole ich mir den \"Thought\" as String\n",
    "                model_thought = thought_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "                # und speichere den \"Thought\" im aktuellen Kommentar Dict ab.\n",
    "                comment[\"openai_thought\"] = model_thought\n",
    "\n",
    "                # Mit dem \"Thought\" kann ich jetzt die Prompt Messages für die finale Annotation erstellen.\n",
    "                messages = cot_few_shot_FINAL_ANNOTATION_prompt_messages(\n",
    "                    prev_cot_messages=few_shot_cot_thought_messages,\n",
    "                    model_thought=model_thought,\n",
    "                    annotation_prompt=cot_annotation_prompt,\n",
    "                )\n",
    "\n",
    "            # Hier stelle ich jetzt eine OpenAI API Anfrage für die finale Annotation des Kommentar.\n",
    "            response = request_chat_completion(prompt_messages=messages, max_token=max_token)\n",
    "\n",
    "            # Die für die OpenAI Anfrage benötigten Token zähle ich mit.\n",
    "            total_tokens_used = total_tokens_used + response[\"usage\"][\"total_tokens\"]\n",
    "\n",
    "            # Aus der Antwort hole ich mir die finale Annotation as String\n",
    "            model_annotation = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "            # und speichere die finale Annotation im aktuellen Kommentar Dict ab.\n",
    "            comment[\"openai_annotation\"] = model_annotation\n",
    "\n",
    "            # Den annotierten Kommentar füge ich zur späteren Auswerting der \"resuls\" Liste an.\n",
    "            results.append(comment)\n",
    "\n",
    "    # Sollte es zu irgendeinem Fehler komme, fange ich diesen hier ab und gebe den Fehler aus.\n",
    "    except Exception as e:\n",
    "        print(\"[PROMPT EVAL RUN] Ein Fehler ist während der des Prompt Evaluation Durchlauf aufgetreten: \", e)\n",
    "\n",
    "    # Auch wenn ein Fehler während des Durchlauf auftritt, sollen die bisherigen Ergenisse unbedingt gespeichert werden!\n",
    "    finally:\n",
    "        print(f\"[PROMPT EVAL RUN] Für den Durchlauf wurden {total_tokens_used} Token verbraucht. (ca. ${(total_tokens_used/1000)*0.002})\")\n",
    "\n",
    "        # Hier speichere ich die aktullen Ergenisse als Parquet Datei an dem für den Prompt angegebenen Pfad.\n",
    "        results_df = pl.from_dicts(results)\n",
    "        write_annotations_to_comment_dataset(eval_results_parquet_path, results_df)\n",
    "\n",
    "        # Die bisherigen Ergebnisse gebe ich am Ende der Funktion immer zurück.\n",
    "        return pl.read_parquet(eval_results_parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluationsmetriken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report (f1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.50      1.00      0.67         2\n",
      "           b       1.00      0.50      0.67         2\n",
      "           c       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.83      0.67      0.67         6\n",
      "weighted avg       0.83      0.67      0.67         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calcuate_classification_report(df, annotation_columns):\n",
    "    reliability_data = df.select(annotation_columns).to_numpy().astype(\"U\").T\n",
    "\n",
    "    y_true = reliability_data[0]\n",
    "    y_pred = reliability_data[1]\n",
    "\n",
    "    classification_report_str = classification_report(y_true, y_pred)\n",
    "    classification_report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "    return classification_report_str, classification_report_dict\n",
    "\n",
    "\n",
    "data = [\n",
    "    [\"a\", \"b\", \"c\", \"a\", \"b\", \"c\"],\n",
    "    [\"a\", \"b\", \"a\", \"a\", \"a\", \"c\"],\n",
    "]\n",
    "\n",
    "annotation_col_names = [\"y_true\", \"y_pred\"]\n",
    "df = pl.DataFrame(schema=annotation_col_names, data=data)\n",
    "\n",
    "classification_report_str, classification_report_dict = calcuate_classification_report(df, annotation_col_names)\n",
    "\n",
    "\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krippendorff's Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorf's alpah:  0.5111\n"
     ]
    }
   ],
   "source": [
    "def calculate_krippendorf(df, annotation_columns):\n",
    "    reliability_data = df.select(annotation_columns).to_numpy().astype(\"U\").T\n",
    "    try:\n",
    "        kripps_alpha = krippendorff.alpha(reliability_data=reliability_data, level_of_measurement=\"nominal\")\n",
    "    except Exception as e:\n",
    "        print(\"[METRICS] Error while calculating Krippendorf's alpha: \", e)\n",
    "        kripps_alpha = -1\n",
    "\n",
    "    return round(kripps_alpha, 4)\n",
    "\n",
    "\n",
    "data = [\n",
    "    [\"a\", \"b\", \"c\", \"a\", \"b\", \"c\"],\n",
    "    [\"a\", \"b\", \"a\", \"a\", \"a\", \"c\"],\n",
    "    # [\"a\", \"a\", \"a\", \"a\", \"a\", \"a\"],\n",
    "    # [\"a\", \"a\", \"a\", \"a\", \"a\", \"a\"],\n",
    "]\n",
    "annotation_col_names = [\"y_true\", \"y_pred\"]\n",
    "df = pl.DataFrame(schema=annotation_col_names, data=data)\n",
    "\n",
    "print(\"Krippendorf's alpah: \", calculate_krippendorf(df, annotation_col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umwandeln der Annotationen\n",
    "\n",
    "Mit folgender Hilfsfunktion kann ich anhand eines \"annotation_mappings\" die OpenAI Model Annotationen in mein eignes Annotationsschame umwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die umgewandelten Annotationen: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>comment_id</th><th>openai_thought</th><th>openai_annotation</th></tr><tr><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>28215451441</td><td>&quot;Gedanke 01&quot;</td><td>&quot;s&quot;</td></tr><tr><td>39124746764</td><td>&quot;Gedanke 02&quot;</td><td>&quot;a&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 3)\n",
       "┌─────────────┬────────────────┬───────────────────┐\n",
       "│ comment_id  ┆ openai_thought ┆ openai_annotation │\n",
       "│ ---         ┆ ---            ┆ ---               │\n",
       "│ i64         ┆ str            ┆ str               │\n",
       "╞═════════════╪════════════════╪═══════════════════╡\n",
       "│ 28215451441 ┆ Gedanke 01     ┆ s                 │\n",
       "│ 39124746764 ┆ Gedanke 02     ┆ a                 │\n",
       "└─────────────┴────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_prompt_eval_results(df, annotation_mappings):\n",
    "    # Ersetzt die vordefinierten \"annotation_options\" mit meinen eigenen Annotationen.\n",
    "    for annotation_mapping in annotation_mappings:\n",
    "        for annotation_option, annotation in list(annotation_mapping.items()):\n",
    "            df = df.with_columns(\n",
    "                pl.when(pl.col(\"openai_annotation\").str.starts_with(annotation_option))\n",
    "                .then(pl.lit(annotation))\n",
    "                .otherwise(pl.col(\"openai_annotation\"))\n",
    "                .alias(\"openai_annotation\")\n",
    "            )\n",
    "\n",
    "    # Wenn das OpenAI Model etwas anderes ausgegeben hat, kann es nicht automatisch zu einer Annotation gematchet werden. In diesem\n",
    "    # Fall setze ich die Annotation automatisch auf \"na\".\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"openai_annotation\").is_in(pl.Series(list(annotation_mappings[0].values()))))\n",
    "        .then(pl.col(\"openai_annotation\"))\n",
    "        .otherwise(pl.lit(\"na\"))\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "annotation_mappings = [\n",
    "    {\n",
    "        \"Solidarität\": \"s\",\n",
    "        \"Anti-Solidarität\": \"a\",\n",
    "        \"Nicht-Zutreffend\": \"na\",\n",
    "    },\n",
    "    {\n",
    "        \"Klassifizierung: Solidarität\": \"s\",\n",
    "        \"Klassifizierung: Anti-Solidarität\": \"a\",\n",
    "        \"Klassifizierung: Nicht-Zutreffend\": \"na\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt_eval_results_df = pl.DataFrame(\n",
    "    [\n",
    "        {\"comment_id\": 28215451441, \"openai_thought\": \"Gedanke 01\", \"openai_annotation\": \"Solidarität\"},\n",
    "        {\"comment_id\": 39124746764, \"openai_thought\": \"Gedanke 02\", \"openai_annotation\": \"Klassifizierung: Anti-Solidarität\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "example_parsed_prompt_eval_results_df = parse_prompt_eval_results(example_prompt_eval_results_df, annotation_mappings=annotation_mappings)\n",
    "\n",
    "print(\"Die umgewandelten Annotationen: \")\n",
    "example_parsed_prompt_eval_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonstige Hilfsfunktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evaluation_metrics(df, annotation_columns=[\"annotation\", \"openai_annotation\"]):\n",
    "    classification_report_str, classification_report_dict = calcuate_classification_report(df, annotation_columns=annotation_columns)\n",
    "    kripps_alpha = calculate_krippendorf(df, annotation_columns=annotation_columns)\n",
    "    return classification_report_str, classification_report_dict, kripps_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_results_df_between_timeframes(df):\n",
    "    df_2015 = df.clone().filter(pl.col(\"created_utc\") < pl.date(2020, 1, 1))\n",
    "    df_2022 = df.clone().filter(pl.col(\"created_utc\") > pl.date(2020, 1, 1))\n",
    "    return df_2015, df_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_pipeline(\n",
    "    prompt_name,\n",
    "    prompt_type,\n",
    "    eval_results_parquet_path,\n",
    "    annotated_comments_df,\n",
    "    system_prompt,\n",
    "    cot_annotation_prompt=\"\",\n",
    "    few_shot_examples=[],\n",
    "):\n",
    "    # Hier starte ich eine Prompt-Evaluation Durchlauf\n",
    "    prompt_eval_results_df = prompt_evaluation_run(\n",
    "        annotated_comments_df=annotated_comments_df,\n",
    "        prompt_type=prompt_type,\n",
    "        eval_results_parquet_path=eval_results_parquet_path,\n",
    "        system_prompt=system_prompt,\n",
    "        cot_annotation_prompt=cot_annotation_prompt,\n",
    "        few_shot_examples=few_shot_examples,\n",
    "    )\n",
    "\n",
    "    # Join mit original annotierten Kommentar Dataset\n",
    "    if prompt_type in [\"ZERO_SHOT\", \"FEW_SHOT\"]:\n",
    "        annotation_column_names = [\"openai_annotation\"]\n",
    "    elif prompt_type in [\"CHAIN_OF_THOUGHT\", \"FEW_SHOT_CHAIN_OF_THOUGHT\"]:\n",
    "        annotation_column_names = [\"openai_annotation\", \"openai_thought\"]\n",
    "\n",
    "    prompt_eval_results_df = annotated_comments_df.clone().join(\n",
    "        prompt_eval_results_df.select([\"comment_id\"] + annotation_column_names), on=\"comment_id\"\n",
    "    )\n",
    "\n",
    "    # Ich \"groupe\" alle OpenAI Model Annotationen und lasse sie nach absteigender Häufigkeit anzeigen.\n",
    "    grouped_model_annotations = prompt_eval_results_df.groupby(\"openai_annotation\").count().sort(\"count\", descending=True)\n",
    "    print(\"\\n[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen: \", grouped_model_annotations)\n",
    "\n",
    "    # Hier wandel ich die OpenAI Model Annotationen in mein eigenes Annotationschema um.\n",
    "    parsed_prompt_eval_results_df = parse_prompt_eval_results(df=prompt_eval_results_df, annotation_mappings=annotation_mappings)\n",
    "    print(\"\\n[PIPELINE] Umgewandelte OpenAI Model Annotationen: \", parsed_prompt_eval_results_df.groupby(\"openai_annotation\").count())\n",
    "\n",
    "    # Für diese umgwandelten Annotationen kann ich mir jetzt die Evaluationsmetriken erstellen.\n",
    "    classification_report_str, classification_report_dict, kripps_alpha = calculate_evaluation_metrics(parsed_prompt_eval_results_df)\n",
    "    print(f\"\\n[PIPELINE] Krippendorf's Alpha: {round(kripps_alpha, 4)}\")\n",
    "    print(\"\\n[PIPELINE] Classification Report:\\n\\n\", classification_report_str)\n",
    "\n",
    "    # Die Evaluationsmetriken lasse ich mir auch getrennt für die zwei Zeiträume ausgeben.\n",
    "    df_2015, df_2022 = split_results_df_between_timeframes(parsed_prompt_eval_results_df)\n",
    "\n",
    "    classification_report_str_2015, _, kripps_alpha_2015 = calculate_evaluation_metrics(df_2015)\n",
    "    print(f\"\\n[PIPELINE] Krippendorf's Alpha 2015: {round(kripps_alpha_2015, 4)}\")\n",
    "    print(\"\\n[PIPELINE] Classification Report 2015:\\n\\n\", classification_report_str_2015)\n",
    "\n",
    "    classification_report_str_2022, _, kripps_alpha_2022 = calculate_evaluation_metrics(df_2022)\n",
    "    print(f\"\\n[PIPELINE] Krippendorf's Alpha 2022: {round(kripps_alpha_2022, 4)}\")\n",
    "    print(\"\\n[PIPELINE] Classification Report 2022:\\n\\n\", classification_report_str_2022)\n",
    "\n",
    "    # Zum Schluss gebe ich immer ein Dict mit den wichtigsten Evaluationsmetriken zurück.\n",
    "    return {\n",
    "        \"prompt\": prompt_name,\n",
    "        \"accuracy\": classification_report_dict.get(\"accuracy\"),\n",
    "        \"macro f1-score\": classification_report_dict[\"macro avg\"][\"f1-score\"],\n",
    "        \"kripps_alpha\": kripps_alpha,\n",
    "    }\n",
    "\n",
    "\n",
    "# example_system_prompt = \"Klassifiziere folgenden Social-Media-Kommentar mit Solidarität, Anti-Solidarität, oder Nicht-Zutreffend.\"\n",
    "# prompt_name = \"00 EXAMPLE TEST RUN\"\n",
    "# prompt_type = \"ZERO_SHOT\"\n",
    "# parquet_path = \"datasets/results/00_example_run_annotations.parquet\"\n",
    "\n",
    "# prompt_pipeline(\n",
    "#     prompt_name=prompt_name,\n",
    "#     prompt_type=prompt_type,\n",
    "#     eval_results_parquet_path=parquet_path,\n",
    "#     annotated_comments_df=annotated_comments_df.limit(100),\n",
    "#     system_prompt=example_system_prompt,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 First Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (681, 2)\n",
      "┌───────────────────────────────────┬───────┐\n",
      "│ openai_annotation                 ┆ count │\n",
      "│ ---                               ┆ ---   │\n",
      "│ str                               ┆ u32   │\n",
      "╞═══════════════════════════════════╪═══════╡\n",
      "│ Anti-Solidarität gegenüber Flüch… ┆ 85    │\n",
      "│ Der Kommentar drückt Anti-Solida… ┆ 82    │\n",
      "│ Solidarität gegenüber Flüchtling… ┆ 41    │\n",
      "│ Der Kommentar drückt Solidarität… ┆ 31    │\n",
      "│ …                                 ┆ …     │\n",
      "│ Der gegebene Kommentar drückt An… ┆ 1     │\n",
      "│ Der Kommentar drückt Solidarität… ┆ 1     │\n",
      "│ Der Kommentar drückt Anti-Solida… ┆ 1     │\n",
      "│ Der gegebene Kommentar drückt An… ┆ 1     │\n",
      "└───────────────────────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ a                 ┆ 100   │\n",
      "│ na                ┆ 828   │\n",
      "│ s                 ┆ 72    │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.0524\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.08      0.12      0.10        68\n",
      "          na       0.84      0.83      0.84       838\n",
      "           s       0.26      0.20      0.23        94\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.39      0.38      0.39      1000\n",
      "weighted avg       0.73      0.72      0.73      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.0019\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.11      0.11      0.11        63\n",
      "          na       0.77      0.81      0.79       389\n",
      "           s       0.28      0.17      0.21        48\n",
      "\n",
      "    accuracy                           0.66       500\n",
      "   macro avg       0.39      0.36      0.37       500\n",
      "weighted avg       0.64      0.66      0.65       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: 0.1034\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.03      0.20      0.05         5\n",
      "          na       0.91      0.85      0.88       449\n",
      "           s       0.26      0.24      0.25        46\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.40      0.43      0.39       500\n",
      "weighted avg       0.84      0.79      0.81       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"01 First Try\"\n",
    "prompt_type = \"ZERO_SHOT\"\n",
    "parquet_path = \"datasets/results/01_first_try_annotations.parquet\"\n",
    "\n",
    "prompt_01_first_try = \"Annotiere den gegebenen Social-Media-Kommentar zu dem Thema Flüchtlinge, Geflüchtete oder Asyl. Bestimme dabei, ob der Kommentar Solidarität oder Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten ausdrückt, oder ob er nicht zutreffend ist.\"\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_01_first_try,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Zero Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (14, 2)\n",
      "┌───────────────────────────────────┬───────┐\n",
      "│ openai_annotation                 ┆ count │\n",
      "│ ---                               ┆ ---   │\n",
      "│ str                               ┆ u32   │\n",
      "╞═══════════════════════════════════╪═══════╡\n",
      "│ Nicht-Zutreffend                  ┆ 458   │\n",
      "│ Anti-Solidarität                  ┆ 442   │\n",
      "│ Solidarität                       ┆ 89    │\n",
      "│ Der gegebene Kommentar betrifft … ┆ 1     │\n",
      "│ …                                 ┆ …     │\n",
      "│ Nicht-Zutreffend. Der Kommentar … ┆ 1     │\n",
      "│ Es tut mir leid, aber ich kann d… ┆ 1     │\n",
      "│ Der Kommentar wird mit Solidarit… ┆ 1     │\n",
      "│ Vielen Dank für die Klarstellung… ┆ 1     │\n",
      "└───────────────────────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ s                 ┆ 89    │\n",
      "│ a                 ┆ 442   │\n",
      "│ na                ┆ 469   │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.0856\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.15      0.99      0.26        68\n",
      "          na       0.93      0.52      0.67       838\n",
      "           s       0.44      0.41      0.43        94\n",
      "\n",
      "    accuracy                           0.54      1000\n",
      "   macro avg       0.51      0.64      0.45      1000\n",
      "weighted avg       0.83      0.54      0.62      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.1327\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.24      0.98      0.38        63\n",
      "          na       0.93      0.49      0.64       389\n",
      "           s       0.50      0.33      0.40        48\n",
      "\n",
      "    accuracy                           0.54       500\n",
      "   macro avg       0.55      0.60      0.47       500\n",
      "weighted avg       0.80      0.54      0.58       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: -0.0053\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.03      1.00      0.05         5\n",
      "          na       0.94      0.55      0.69       449\n",
      "           s       0.40      0.50      0.45        46\n",
      "\n",
      "    accuracy                           0.55       500\n",
      "   macro avg       0.46      0.68      0.40       500\n",
      "weighted avg       0.88      0.55      0.66       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"02 Zero Shot Prompt\"\n",
    "prompt_type = \"ZERO_SHOT\"\n",
    "parquet_path = \"datasets/results/02_zero_shot_annotations.parquet\"\n",
    "\n",
    "prompt_02_zero_shot = \"\"\"Annotieren Sie den gegebenen Social-Media-Kommentar zu dem Thema Flüchtlinge, Geflüchtete oder Asyl. Bestimmen Sie dabei, ob der Kommentar Solidarität oder Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten ausdrückt, oder ob er nicht zutreffend ist. Verwenden Sie dafür die folgenden Leitlinien.\n",
    "\n",
    "Leitlinien:\n",
    "\n",
    "Definition von Solidarität:\n",
    "Die Bereitschaft, die eigenen Ressourcen mit anderen zu teilen, sei es direkt, indem man Geld oder Zeit zur Unterstützung anderer spendet, oder indirekt, indem man den Staat dabei unterstützt, einen Teil der durch Steuern oder Beiträge eingenommenen staatlichen Mittel auszugeben und umzuverteilen.\n",
    "\n",
    "Allgemeine Regeln:\n",
    "1.\tBerücksichtigen Sie keine Links (urls) bei der Annotation.\n",
    "2.\tIronie und Sarkasmus in Kommentaren müssen berücksichtigt werden.\n",
    "\n",
    "Detaillierte Regeln für die Annotation:\n",
    "1.\tEin Kommentar wird mit Solidarität annotiert, wenn:\n",
    "a.\tDer Kommentar eindeutig den Willen zur Unterstützung, die Bereitschaft zum Teilen von Ressourcen und/oder zum Leisten von Hilfe zeigt.\n",
    "b.\tDer Kommentar eine positive Einstellung und Dankbarkeit gegenüber denjenigen zeigt, die Ressourcen teilen und/oder helfen.\n",
    "c.\tDer Kommentar die Europäische Union als Solidaritätsunion befürwortet.\n",
    "d.\tDer Kommentar die EU dafür kritisiert, dass sie nicht genug tut, um Ressourcen zu teilen und/oder zu helfen.\n",
    "e.\tDer Kommentar selbst Hilfe leistet, indem er Informationen teilt oder zur Hilfe und Unterstützung aufruft. \n",
    "\n",
    "2.\tEin Kommentar wird mit Anti-Solidarität annotiert, wenn:\n",
    "a.\tDer Kommentar eindeutig zeigt, dass kein Wille zur Unterstützung, keine Bereitschaft zum Teilen von Ressourcen und/oder keine Absicht zum Leisten von Hilfe besteht.\n",
    "b.\tDer Kommentar vorschlägt, Flüchtlinge/Geflüchtete von Ressourcen auszuschließen, zu denen sie derzeit Zugang haben.\n",
    "c.\tDer Kommentar Tendenzen zum Nationalismus und zum Schließen von Grenzen zeigt.\n",
    "d.\tDer Kommentar Flüchtlinge/Geflüchtete als schädlich und/oder schlecht für die Gesellschaft betrachtet.\n",
    "\n",
    "3.\tEin Kommentar wird mit Nicht-Zutreffend annotiert, wenn:\n",
    "a.\tDer Kommentar nicht eindeutig mit Solidarität oder Anti-Solidarität annotiert werden kann, weil zusätzliche Informationen fehlen.\n",
    "b.\tDer Kommentar keinen Hinweis auf Solidarität oder Anti-Solidarität zeigt.\n",
    "c.\tDer Kommentar andere Themen als Solidarität oder Anti-Solidarität betrifft.\n",
    "d.\tDer Kommentar nicht verständlich ist (enthält z.B. nur Links).\"\"\"\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_02_zero_shot,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Zero Shot Prompt Re1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (75, 2)\n",
      "┌───────────────────────────────────┬───────┐\n",
      "│ openai_annotation                 ┆ count │\n",
      "│ ---                               ┆ ---   │\n",
      "│ str                               ┆ u32   │\n",
      "╞═══════════════════════════════════╪═══════╡\n",
      "│ Nicht-Zutreffend                  ┆ 470   │\n",
      "│ Anti-Solidarität                  ┆ 323   │\n",
      "│ Solidarität                       ┆ 130   │\n",
      "│ Nicht zutreffend                  ┆ 6     │\n",
      "│ …                                 ┆ …     │\n",
      "│ Der gegebene Kommentar drückt An… ┆ 1     │\n",
      "│ Der Kommentar drückt Solidarität… ┆ 1     │\n",
      "│ Der gegebene Kommentar drückt An… ┆ 1     │\n",
      "│ Der Kommentar drückt Anti-Solida… ┆ 1     │\n",
      "└───────────────────────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ a                 ┆ 323   │\n",
      "│ na                ┆ 547   │\n",
      "│ s                 ┆ 130   │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.1169\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.14      0.68      0.24        68\n",
      "          na       0.90      0.59      0.71       838\n",
      "           s       0.35      0.48      0.40        94\n",
      "\n",
      "    accuracy                           0.58      1000\n",
      "   macro avg       0.46      0.58      0.45      1000\n",
      "weighted avg       0.80      0.58      0.65      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.166\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.22      0.68      0.33        63\n",
      "          na       0.88      0.57      0.69       389\n",
      "           s       0.41      0.46      0.43        48\n",
      "\n",
      "    accuracy                           0.57       500\n",
      "   macro avg       0.50      0.57      0.49       500\n",
      "weighted avg       0.75      0.57      0.62       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: 0.0291\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.02      0.60      0.04         5\n",
      "          na       0.93      0.61      0.73       449\n",
      "           s       0.30      0.50      0.38        46\n",
      "\n",
      "    accuracy                           0.60       500\n",
      "   macro avg       0.42      0.57      0.39       500\n",
      "weighted avg       0.86      0.60      0.69       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"03 Zero Shot Prompt Re1\"\n",
    "prompt_type = \"ZERO_SHOT\"\n",
    "parquet_path = \"datasets/results/03_zero_shot_re1_annotations.parquet\"\n",
    "\n",
    "prompt_03_zero_shot_re1 = \"\"\"Klassifizieren Sie den gegebenen Social-Media-Kommentar zu dem Thema Flüchtlinge, Geflüchtete oder Asyl. Bestimmen Sie dabei, ob der Kommentar Solidarität oder Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten ausdrückt, oder ob er nicht zutreffend ist. Verwenden Sie dafür die folgenden Leitlinien.\n",
    "\n",
    "Leitlinien:\n",
    "\n",
    "Definition von Solidarität:\n",
    "Die Bereitschaft, die eigenen Ressourcen mit anderen zu teilen, sei es direkt, indem man Geld oder Zeit zur Unterstützung anderer spendet, oder indirekt, indem man den Staat dabei unterstützt, einen Teil der durch Steuern oder Beiträge eingenommenen staatlichen Mittel auszugeben und umzuverteilen.\n",
    "\n",
    "Allgemeine Regeln:\n",
    "1.\tBerücksichtigen Sie keine Links (urls) bei der Annotation.\n",
    "2.\tIronie und Sarkasmus in Kommentaren müssen berücksichtigt werden. \n",
    "\n",
    "Detaillierte Regeln für die Annotation:\n",
    "1.\tEin Kommentar wird mit Solidarität annotiert, wenn:\n",
    "a.\tDer Kommentar eindeutig den Willen zur Unterstützung, die Bereitschaft zum Teilen von Ressourcen und/oder zum Leisten von Hilfe zeigt.\n",
    "b.\tDer Kommentar eine positive Einstellung und Dankbarkeit gegenüber denjenigen zeigt, die Ressourcen teilen und/oder helfen.\n",
    "c.\tDer Kommentar die Europäische Union als Solidaritätsunion befürwortet.\n",
    "d.\tDer Kommentar die EU dafür kritisiert, dass sie nicht genug tut, um Ressourcen zu teilen und/oder zu helfen.\n",
    "e.\tDer Kommentar selbst Hilfe leistet, indem er Informationen teilt oder zur Hilfe und Unterstützung aufruft. \n",
    "\n",
    "2.\tEin Kommentar wird mit Anti-Solidarität annotiert, wenn:\n",
    "a.\tDer Kommentar eindeutig zeigt, dass kein Wille zur Unterstützung, keine Bereitschaft zum Teilen von Ressourcen und/oder keine Absicht zum Leisten von Hilfe besteht.\n",
    "b.\tDer Kommentar vorschlägt, Flüchtlinge/Geflüchtete von Ressourcen auszuschließen, zu denen sie derzeit Zugang haben.\n",
    "c.\tDer Kommentar Tendenzen zum Nationalismus und zum Schließen von Grenzen zeigt.\n",
    "d.\tDer Kommentar Flüchtlinge/Geflüchtete als schädlich und/oder schlecht für die Gesellschaft betrachtet.\n",
    "\n",
    "3.\tEin Kommentar wird mit Nicht-Zutreffend annotiert, wenn:\n",
    "a.\tDer Kommentar nicht eindeutig mit Solidarität oder Anti-Solidarität annotiert werden kann, weil zusätzliche Informationen fehlen.\n",
    "b.\tDer Kommentar keinen Hinweis auf Solidarität oder Anti-Solidarität zeigt.\n",
    "c.\tDer Kommentar andere Themen als Solidarität oder Anti-Solidarität betrifft.\n",
    "d.\tDer Kommentar nicht verständlich ist (enthält z.B. nur Links).\"\"\"\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_03_zero_shot_re1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Zero Shot Prompt Re2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (4, 2)\n",
      "┌───────────────────────────────────┬───────┐\n",
      "│ openai_annotation                 ┆ count │\n",
      "│ ---                               ┆ ---   │\n",
      "│ str                               ┆ u32   │\n",
      "╞═══════════════════════════════════╪═══════╡\n",
      "│ Nicht-Zutreffend                  ┆ 468   │\n",
      "│ Anti-Solidarität                  ┆ 443   │\n",
      "│ Solidarität                       ┆ 88    │\n",
      "│ Entschuldigung, aber ich kann Ih… ┆ 1     │\n",
      "└───────────────────────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ a                 ┆ 443   │\n",
      "│ na                ┆ 469   │\n",
      "│ s                 ┆ 88    │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.0813\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.15      0.99      0.26        68\n",
      "          na       0.93      0.52      0.67       838\n",
      "           s       0.44      0.41      0.43        94\n",
      "\n",
      "    accuracy                           0.54      1000\n",
      "   macro avg       0.51      0.64      0.45      1000\n",
      "weighted avg       0.83      0.54      0.62      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.1322\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.23      0.98      0.37        63\n",
      "          na       0.94      0.46      0.62       389\n",
      "           s       0.53      0.44      0.48        48\n",
      "\n",
      "    accuracy                           0.53       500\n",
      "   macro avg       0.57      0.63      0.49       500\n",
      "weighted avg       0.81      0.53      0.58       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: -0.0301\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.03      1.00      0.06         5\n",
      "          na       0.92      0.57      0.70       449\n",
      "           s       0.38      0.39      0.38        46\n",
      "\n",
      "    accuracy                           0.56       500\n",
      "   macro avg       0.44      0.65      0.38       500\n",
      "weighted avg       0.86      0.56      0.67       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"04 Zero Shot Prompt Re2\"\n",
    "prompt_type = \"ZERO_SHOT\"\n",
    "parquet_path = \"datasets/results/04_zero_shot_re2_annotations.parquet\"\n",
    "\n",
    "prompt_04_zero_shot_re2 = \"\"\"Klassifizieren Sie den gegebenen Social-Media-Kommentar zu dem Thema Flüchtlinge, Geflüchtete oder Asyl. Bestimmen Sie dabei, ob der Kommentar Solidarität oder Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten ausdrückt, oder ob er nicht zutreffend ist. Verwenden Sie dafür die folgenden Leitlinien.\n",
    "Leitlinien:\n",
    "Solidarität ist die Bereitschaft, die eigenen Ressourcen mit anderen zu teilen, sei es direkt, indem man Geld oder Zeit zur Unterstützung anderer spendet, oder indirekt, indem man den Staat dabei unterstützt, einen Teil der durch Steuern oder Beiträge eingenommenen staatlichen Mittel auszugeben und umzuverteilen.\n",
    "Es gibt drei allgemeine Regeln für die Klassifizierung. Erstens dürfen beim Klassifizieren keine Links (URLs) berücksichtigt werden. Zweitens müssen Ironie und Sarkasmus beim Klassifizieren berücksichtigt werden. Drittens klassifizieren Sie nur mit den Wörtern Solidarität, Anti-Solidarität oder Nicht-Zutreffend. Schreiben Sie nichts anderes.\n",
    "Für das Klassifizieren in die Klassen Solidarität, Anti-Solidarität und Nicht-Zutreffend gibt es detaillierte Regeln.\n",
    "Ein Kommentar wird mit Solidarität klassifiziert, wenn der Kommentar eindeutig den Willen zur Unterstützung, die Bereitschaft zum Teilen von Ressourcen und/oder zum Leisten von Hilfe zeigt, der Kommentar eine positive Einstellung und Dankbarkeit gegenüber denjenigen zeigt, die Ressourcen teilen und/oder helfen, der Kommentar die Europäische Union als Solidaritätsunion befürwortet, der Kommentar die EU dafür kritisiert, dass sie nicht genug tut, um Ressourcen zu teilen und/oder zu helfen oder der Kommentar selbst Hilfe leistet, indem er Informationen teilt oder zur Hilfe und Unterstützung aufruft.\n",
    "Ein Kommentar wird mit Anti-Solidarität klassifiziert, wenn der Kommentar eindeutig zeigt, dass kein Wille zur Unterstützung, keine Bereitschaft zum Teilen von Ressourcen und/oder keine Absicht zum Leisten von Hilfe besteht, der Kommentar vorschlägt, Flüchtlinge/Geflüchtete von Ressourcen auszuschließen, zu denen sie derzeit Zugang haben, der Kommentar Tendenzen zum Nationalismus und zum Schließen von Grenzen zeigt oder der Kommentar Flüchtlinge/Geflüchtete als schädlich und/oder schlecht für die Gesellschaft betrachtet.\n",
    "Ein Kommentar wird mit Nicht-Zutreffend klassifiziert, wenn der Kommentar nicht eindeutig mit Solidarität oder Anti-Solidarität annotiert werden kann, weil zusätzliche Informationen fehlen, der Kommentar keinen Hinweis auf Solidarität oder Anti-Solidarität zeigt, der Kommentar andere Themen als Solidarität oder Anti-Solidarität betrifft oder der Kommentar nicht verständlich ist (enthält z.B. nur Links).\"\"\"\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_04_zero_shot_re2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 Zero Shot Persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (268, 2)\n",
      "┌───────────────────────────────────┬───────┐\n",
      "│ openai_annotation                 ┆ count │\n",
      "│ ---                               ┆ ---   │\n",
      "│ str                               ┆ u32   │\n",
      "╞═══════════════════════════════════╪═══════╡\n",
      "│ Nicht-Zutreffend                  ┆ 270   │\n",
      "│ Klassifizierung: Anti-Solidaritä… ┆ 201   │\n",
      "│ Klassifizierung: Nicht-Zutreffen… ┆ 180   │\n",
      "│ Solidarität                       ┆ 57    │\n",
      "│ …                                 ┆ …     │\n",
      "│ Klassifizierung: Solidarität      ┆ 1     │\n",
      "│                                   ┆       │\n",
      "│ Be…                               ┆       │\n",
      "│ Klassifizierung: Anti-Solidaritä… ┆ 1     │\n",
      "│ Klassifizierung: Solidarität      ┆ 1     │\n",
      "│                                   ┆       │\n",
      "│ Be…                               ┆       │\n",
      "│ Klassifizierung: Anti-Solidaritä… ┆ 1     │\n",
      "└───────────────────────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ s                 ┆ 128   │\n",
      "│ na                ┆ 536   │\n",
      "│ a                 ┆ 336   │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.1687\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.18      0.87      0.29        68\n",
      "          na       0.93      0.59      0.72       838\n",
      "           s       0.39      0.53      0.45        94\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.50      0.66      0.49      1000\n",
      "weighted avg       0.82      0.60      0.67      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.2278\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.26      0.86      0.40        63\n",
      "          na       0.91      0.56      0.69       389\n",
      "           s       0.47      0.54      0.50        48\n",
      "\n",
      "    accuracy                           0.60       500\n",
      "   macro avg       0.55      0.65      0.53       500\n",
      "weighted avg       0.79      0.60      0.64       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: 0.062\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.04      1.00      0.07         5\n",
      "          na       0.94      0.62      0.75       449\n",
      "           s       0.33      0.52      0.40        46\n",
      "\n",
      "    accuracy                           0.61       500\n",
      "   macro avg       0.43      0.71      0.41       500\n",
      "weighted avg       0.87      0.61      0.71       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"05 Zero Shot Persona\"\n",
    "prompt_type = \"ZERO_SHOT\"\n",
    "parquet_path = \"datasets/results/05_zero_shot_persona_annotations.parquet\"\n",
    "\n",
    "prompt_05_zero_shot_persona = \"\"\"Du bist ein wissenschaftlicher Mitarbeiter in einem Forschungsprojekt und hast die Aufgabe, Social-Media-Kommentare zu klassifizieren. Das Forschungsprojekt untersucht die Solidarität gegenüber Flüchtlingen und Geflüchteten in Deutschland. Klassifiziere den gegebenen Social-Media Kommentar zu dem Thema Flüchtlinge, Geflüchtete oder Asyl. Bestimme dabei, ob der Kommentar Solidarität oder Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten ausdrückt, oder ob er nicht-zutreffend ist. Verwende dafür die folgenden Leitlinien.\n",
    "\n",
    "Leitlinien:\n",
    "Definition von Solidarität:\n",
    "Die Bereitschaft, die eigenen Ressourcen mit anderen zu teilen, sei es direkt, indem man Geld oder Zeit zur Unterstützung anderer spendet, oder indirekt, indem man den Staat dabei unterstützt, einen Teil der durch Steuern oder Beiträge eingenommenen staatlichen Mittel auszugeben und umzuverteilen.\n",
    "\n",
    "Allgemeine Regeln:\n",
    "1.\tBerücksichtige keine Links (URLs) bei der Klassifizierung.\n",
    "2.\tIronie und Sarkasmus in Kommentaren müssen berücksichtigt werden.\n",
    "\n",
    "Detaillierte Regeln für die Klassifizierung:\n",
    "1.\tEin Kommentar wird mit Solidarität klassifiziert, wenn:\n",
    "a.\tDer Kommentar eindeutig den Willen zur Unterstützung, die Bereitschaft zum Teilen von Ressourcen und/oder zum Leisten von Hilfe zeigt.\n",
    "b.\tDer Kommentar eine positive Einstellung und Dankbarkeit gegenüber denjenigen zeigt, die Ressourcen teilen und/oder helfen.\n",
    "c.\tDer Kommentar die Europäische Union als Solidaritätsunion befürwortet.\n",
    "d.\tDer Kommentar die EU dafür kritisiert, dass sie nicht genug tut, um Ressourcen zu teilen und/oder zu helfen.\n",
    "e.\tDer Kommentar selbst Hilfe leistet, indem er Informationen teilt oder zur Hilfe und Unterstützung aufruft. \n",
    "\n",
    "2.\tEin Kommentar wird mit Anti-Solidarität klassifiziert, wenn:\n",
    "a.\tDer Kommentar eindeutig zeigt, dass kein Wille zur Unterstützung, keine Bereitschaft zum Teilen von Ressourcen und/oder keine Absicht zum Leisten von Hilfe besteht.\n",
    "b.\tDer Kommentar vorschlägt, Flüchtlinge/Geflüchtete von Ressourcen auszuschließen, zu denen sie derzeit Zugang haben.\n",
    "c.\tDer Kommentar Tendenzen zum Nationalismus und zum Schließen von Grenzen zeigt.\n",
    "d.\tDer Kommentar Flüchtlinge/Geflüchtete als schädlich und/oder schlecht für die Gesellschaft betrachtet.\n",
    "\n",
    "3.\tEin Kommentar wird mit Nicht-Zutreffend klassifiziert, wenn:\n",
    "a.\tDer Kommentar nicht eindeutig mit Solidarität oder Anti-Solidarität annotiert werden kann, weil zusätzliche Informationen fehlen.\n",
    "b.\tDer Kommentar keinen Hinweis auf Solidarität oder Anti-Solidarität zeigt.\n",
    "c.\tDer Kommentar andere Themen als Solidarität oder Anti-Solidarität betrifft.\n",
    "d.\tDer Kommentar nicht verständlich ist (enthält z.B. nur Links).\"\"\"\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_05_zero_shot_persona,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 Zero Shot Persona Re1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (328, 2)\n",
      "┌───────────────────────────────────┬───────┐\n",
      "│ openai_annotation                 ┆ count │\n",
      "│ ---                               ┆ ---   │\n",
      "│ str                               ┆ u32   │\n",
      "╞═══════════════════════════════════╪═══════╡\n",
      "│ Nicht-Zutreffend                  ┆ 229   │\n",
      "│ Klassifizierung: Nicht-Zutreffen… ┆ 229   │\n",
      "│ Klassifizierung: Anti-Solidaritä… ┆ 187   │\n",
      "│ Solidarität                       ┆ 30    │\n",
      "│ …                                 ┆ …     │\n",
      "│ Klassifizierung: Solidarität      ┆ 1     │\n",
      "│                                   ┆       │\n",
      "│ Be…                               ┆       │\n",
      "│ Klassifizierung: Nicht-Zutreffen… ┆ 1     │\n",
      "│ Klassifizierung: Solidarität      ┆ 1     │\n",
      "│                                   ┆       │\n",
      "│ Be…                               ┆       │\n",
      "│ Klassifizierung: Anti-Solidaritä… ┆ 1     │\n",
      "└───────────────────────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ na                ┆ 583   │\n",
      "│ a                 ┆ 306   │\n",
      "│ s                 ┆ 111   │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.2021\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.19      0.84      0.30        68\n",
      "          na       0.92      0.64      0.76       838\n",
      "           s       0.41      0.49      0.45        94\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.51      0.66      0.50      1000\n",
      "weighted avg       0.82      0.64      0.70      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.2675\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.28      0.83      0.41        63\n",
      "          na       0.91      0.62      0.74       389\n",
      "           s       0.52      0.50      0.51        48\n",
      "\n",
      "    accuracy                           0.63       500\n",
      "   macro avg       0.57      0.65      0.55       500\n",
      "weighted avg       0.79      0.63      0.67       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: 0.0885\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.04      1.00      0.08         5\n",
      "          na       0.94      0.66      0.78       449\n",
      "           s       0.34      0.48      0.40        46\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.44      0.71      0.42       500\n",
      "weighted avg       0.87      0.65      0.73       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"06 Zero Shot Persona Re1\"\n",
    "prompt_type = \"ZERO_SHOT\"\n",
    "parquet_path = \"datasets/results/06_zero_shot_persona_re1_annotations.parquet\"\n",
    "\n",
    "prompt_06_zero_shot_persona_re1 = \"\"\"Sie sind ein wissenschaftlicher Mitarbeiter in einem Forschungsprojekt und haben die Aufgabe, Social-Media-Kommentare zu klassifizieren. Das Forschungsprojekt untersucht die Solidarität gegenüber Flüchtlingen und Geflüchteten in Deutschland. Klassifizieren Sie den gegebenen Social-Media Kommentar zu dem Thema Flüchtlinge, Geflüchtete oder Asyl. Bestimmen Sie dabei, ob der Kommentar Solidarität oder Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten ausdrückt, oder ob er nicht-zutreffend ist. Verwenden Sie dafür die folgenden Leitlinien.\n",
    "\n",
    "Leitlinien:\n",
    "Definition von Solidarität:\n",
    "Die Bereitschaft, die eigenen Ressourcen mit anderen zu teilen, sei es direkt, indem man Geld oder Zeit zur Unterstützung anderer spendet, oder indirekt, indem man den Staat dabei unterstützt, einen Teil der durch Steuern oder Beiträge eingenommenen staatlichen Mittel auszugeben und umzuverteilen.\n",
    "\n",
    "Allgemeine Regeln:\n",
    "1.\tBerücksichtigen Sie keine Links (URLs) bei der Klassifizierung.\n",
    "2.\tIronie und Sarkasmus in Kommentaren müssen berücksichtigt werden. \n",
    "\n",
    "Detaillierte Regeln für die Klassifizierung:\n",
    "1.\tEin Kommentar wird mit Solidarität klassifiziert, wenn:\n",
    "a.\tDer Kommentar eindeutig den Willen zur Unterstützung, die Bereitschaft zum Teilen von Ressourcen und/oder zum Leisten von Hilfe zeigt.\n",
    "b.\tDer Kommentar eine positive Einstellung und Dankbarkeit gegenüber denjenigen zeigt, die Ressourcen teilen und/oder helfen.\n",
    "c.\tDer Kommentar die Europäische Union als Solidaritätsunion befürwortet.\n",
    "d.\tDer Kommentar die EU dafür kritisiert, dass sie nicht genug tut, um Ressourcen zu teilen und/oder zu helfen.\n",
    "e.\tDer Kommentar selbst Hilfe leistet, indem er Informationen teilt oder zur Hilfe und Unterstützung aufruft. \n",
    "\n",
    "2.\tEin Kommentar wird mit Anti-Solidarität klassifiziert, wenn:\n",
    "a.\tDer Kommentar eindeutig zeigt, dass kein Wille zur Unterstützung, keine Bereitschaft zum Teilen von Ressourcen und/oder keine Absicht zum Leisten von Hilfe besteht.\n",
    "b.\tDer Kommentar vorschlägt, Flüchtlinge/Geflüchtete von Ressourcen auszuschließen, zu denen sie derzeit Zugang haben.\n",
    "c.\tDer Kommentar Tendenzen zum Nationalismus und zum Schließen von Grenzen zeigt.\n",
    "d.\tDer Kommentar Flüchtlinge/Geflüchtete als schädlich und/oder schlecht für die Gesellschaft betrachtet.\n",
    "\n",
    "3.\tEin Kommentar wird mit Nicht-Zutreffend klassifiziert, wenn:\n",
    "a.\tDer Kommentar nicht eindeutig mit Solidarität oder Anti-Solidarität annotiert werden kann, weil zusätzliche Informationen fehlen.\n",
    "b.\tDer Kommentar keinen Hinweis auf Solidarität oder Anti-Solidarität zeigt.\n",
    "c.\tDer Kommentar andere Themen als Solidarität oder Anti-Solidarität betrifft.\n",
    "d.\tDer Kommentar nicht verständlich ist (enthält z.B. nur Links).\"\"\"\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_06_zero_shot_persona_re1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 One Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (5, 2)\n",
      "┌───────────────────────────────────┬───────┐\n",
      "│ openai_annotation                 ┆ count │\n",
      "│ ---                               ┆ ---   │\n",
      "│ str                               ┆ u32   │\n",
      "╞═══════════════════════════════════╪═══════╡\n",
      "│ Anti-Solidarität                  ┆ 461   │\n",
      "│ Nicht-Zutreffend                  ┆ 283   │\n",
      "│ Solidarität                       ┆ 254   │\n",
      "│ 1. Nicht-Zutreffend               ┆ 1     │\n",
      "│ 2. Nicht-Zut…                     ┆       │\n",
      "│ Es tut mir leid, aber ich habe k… ┆ 1     │\n",
      "└───────────────────────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ s                 ┆ 254   │\n",
      "│ na                ┆ 285   │\n",
      "│ a                 ┆ 461   │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.0065\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.15      1.00      0.26        68\n",
      "          na       0.98      0.33      0.50       838\n",
      "           s       0.28      0.77      0.41        94\n",
      "\n",
      "    accuracy                           0.42      1000\n",
      "   macro avg       0.47      0.70      0.39      1000\n",
      "weighted avg       0.86      0.42      0.47      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.0771\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.23      1.00      0.38        63\n",
      "          na       0.98      0.32      0.49       389\n",
      "           s       0.33      0.71      0.45        48\n",
      "\n",
      "    accuracy                           0.45       500\n",
      "   macro avg       0.52      0.68      0.44       500\n",
      "weighted avg       0.83      0.45      0.47       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: -0.0941\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.03      1.00      0.05         5\n",
      "          na       0.97      0.34      0.50       449\n",
      "           s       0.25      0.83      0.39        46\n",
      "\n",
      "    accuracy                           0.39       500\n",
      "   macro avg       0.42      0.72      0.31       500\n",
      "weighted avg       0.90      0.39      0.49       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"07 One Shot\"\n",
    "prompt_type = \"FEW_SHOT\"\n",
    "parquet_path = \"datasets/results/07_one_shot_annotations.parquet\"\n",
    "\n",
    "few_shot_examples = [\n",
    "    (\n",
    "        \"Die meisten Flüchtlinge kommen aber mit der GFK und nicht mit Artikel 16 GG, der ist hier schlicht nicht relevant, sondern hauptsächlich die GFK, die Grundrechtecharta, die UN-Charta und die europäische Menschenrechtskonvention.\",\n",
    "        \"Nicht-Zutreffend\",\n",
    "    )\n",
    "]\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_06_zero_shot_persona_re1,\n",
    "    few_shot_examples=few_shot_examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 Few Shot Demo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (9, 2)\n",
      "┌───────────────────────────────────┬───────┐\n",
      "│ openai_annotation                 ┆ count │\n",
      "│ ---                               ┆ ---   │\n",
      "│ str                               ┆ u32   │\n",
      "╞═══════════════════════════════════╪═══════╡\n",
      "│ Nicht-Zutreffend                  ┆ 489   │\n",
      "│ Anti-Solidarität                  ┆ 320   │\n",
      "│ Solidarität                       ┆ 185   │\n",
      "│ Entschuldigung für das Missverst… ┆ 1     │\n",
      "│ Nicht-Zutreffend (enthält nur ei… ┆ 1     │\n",
      "│ Ironie/Sarkasmus - Nicht-Zutreff… ┆ 1     │\n",
      "│ Nicht-Zutreffend (aufgrund des H… ┆ 1     │\n",
      "│ Ironie/Sarkasmus                  ┆ 1     │\n",
      "│ Ironie/Sarkasmus (Nicht-Zutreffe… ┆ 1     │\n",
      "└───────────────────────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ na                ┆ 495   │\n",
      "│ s                 ┆ 185   │\n",
      "│ a                 ┆ 320   │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.1762\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.19      0.90      0.31        68\n",
      "          na       0.94      0.56      0.70       838\n",
      "           s       0.33      0.65      0.44        94\n",
      "\n",
      "    accuracy                           0.59      1000\n",
      "   macro avg       0.49      0.70      0.48      1000\n",
      "weighted avg       0.83      0.59      0.65      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.229\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.28      0.89      0.43        63\n",
      "          na       0.93      0.53      0.67       389\n",
      "           s       0.37      0.60      0.46        48\n",
      "\n",
      "    accuracy                           0.58       500\n",
      "   macro avg       0.53      0.67      0.52       500\n",
      "weighted avg       0.79      0.58      0.62       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: 0.0821\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.04      1.00      0.08         5\n",
      "          na       0.96      0.58      0.72       449\n",
      "           s       0.30      0.70      0.42        46\n",
      "\n",
      "    accuracy                           0.60       500\n",
      "   macro avg       0.43      0.76      0.41       500\n",
      "weighted avg       0.89      0.60      0.69       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"08 Few Shot Demo 3\"\n",
    "prompt_type = \"FEW_SHOT\"\n",
    "parquet_path = \"datasets/results/08_few_shot_demo3_annotations.parquet\"\n",
    "\n",
    "few_shot_examples = [\n",
    "    (\n",
    "        \"Die meisten Flüchtlinge kommen aber mit der GFK und nicht mit Artikel 16 GG, der ist hier schlicht nicht relevant, sondern hauptsächlich die GFK, die Grundrechtecharta, die UN-Charta und die europäische Menschenrechtskonvention.\",\n",
    "        \"Nicht-Zutreffend\",\n",
    "    ),\n",
    "    (\n",
    "        \"erzähl das Australien, Dänemark, Skandinavien ... 🤦 wenn Deutschland wirklich will kann es. für abgelehnte nur Sachleistungen und Bett wäre ein erster Schritt. die Asylbewerber zahlen würden sich schlagartig halbieren!.\",\n",
    "        \"Anti-Solidarität\",\n",
    "    ),\n",
    "    (\n",
    "        \"Ich hab meinem Rathaus geschrieben, dass ich ein Zimmer für einen oder zwei Flüchtlinge bereitstellen könnte für umsonst. Ka, ob es da richtig ist, aber die werden das wohl weiterleiten.\",\n",
    "        \"Solidarität\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_06_zero_shot_persona_re1,\n",
    "    few_shot_examples=few_shot_examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 Few Shot Demo 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (7, 2)\n",
      "┌───────────────────────────────────┬───────┐\n",
      "│ openai_annotation                 ┆ count │\n",
      "│ ---                               ┆ ---   │\n",
      "│ str                               ┆ u32   │\n",
      "╞═══════════════════════════════════╪═══════╡\n",
      "│ Nicht-Zutreffend                  ┆ 400   │\n",
      "│ Anti-Solidarität                  ┆ 359   │\n",
      "│ Solidarität                       ┆ 236   │\n",
      "│ Ironie erkannt. Nicht-Zutreffend… ┆ 2     │\n",
      "│ Bitte beachten Sie, dass ich kei… ┆ 1     │\n",
      "│ Ironie/Sarkasmus                  ┆ 1     │\n",
      "│ Entschuldigung, aber ich kann Ih… ┆ 1     │\n",
      "└───────────────────────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ na                ┆ 405   │\n",
      "│ s                 ┆ 236   │\n",
      "│ a                 ┆ 359   │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.1112\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.18      0.96      0.30        68\n",
      "          na       0.96      0.46      0.62       838\n",
      "           s       0.28      0.70      0.40        94\n",
      "\n",
      "    accuracy                           0.52      1000\n",
      "   macro avg       0.47      0.71      0.44      1000\n",
      "weighted avg       0.84      0.52      0.58      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.2014\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.29      0.97      0.44        63\n",
      "          na       0.97      0.45      0.61       389\n",
      "           s       0.32      0.71      0.44        48\n",
      "\n",
      "    accuracy                           0.54       500\n",
      "   macro avg       0.52      0.71      0.50       500\n",
      "weighted avg       0.82      0.54      0.58       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: -0.0165\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.03      0.80      0.05         5\n",
      "          na       0.95      0.47      0.63       449\n",
      "           s       0.25      0.70      0.37        46\n",
      "\n",
      "    accuracy                           0.50       500\n",
      "   macro avg       0.41      0.66      0.35       500\n",
      "weighted avg       0.88      0.50      0.60       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"09 Few Shot Demo 10\"\n",
    "prompt_type = \"FEW_SHOT\"\n",
    "parquet_path = \"datasets/results/09_few_shot_demo10_annotations.parquet\"\n",
    "\n",
    "few_shot_examples = [\n",
    "    (\n",
    "        \"Naja. Klappt in Australien oder Israel ja auch einigermaßen? Und ich denke die Investitionen um Europa abzuschotten dürften geringer sein als das was die Flüchtlinge an Kosten nach sich ziehen,\",\n",
    "        \"Anti-Solidarität\",\n",
    "    ),\n",
    "    (\n",
    "        \"Was soll ich als Privatperson denn tun? Ich kann keine Boote ins Mittelmeer schicken, um die Flüchtlinge zu retten. Das können nur die Politiker und NGOs. Ich empfinde es aber trotzdem als wichtig, dass die Bevölkerung ein Zeichen setzt, dass Flüchtlinge willkommen sind. Auch wenn das Video die Welt nicht ändert, ist es doch besser, als bei den ganzen Hetztaten stumm zu bleiben.\",\n",
    "        \"Solidarität\",\n",
    "    ),\n",
    "    (\n",
    "        \"Die meisten Flüchtlinge kommen aber mit der GFK und nicht mit Artikel 16 GG, der ist hier schlicht nicht relevant, sondern hauptsächlich die GFK, die Grundrechtecharta, die UN-Charta und die europäische Menschenrechtskonvention.\",\n",
    "        \"Nicht-Zutreffend\",\n",
    "    ),\n",
    "    (\"Weiß jemand, wie der Anteil von Flüchtlingen ohne Ausweisdokumente vor 2015 war?\", \"Nicht-Zutreffend\"),\n",
    "    (\n",
    "        '\"In sozialen Netzwerken hatten zuletzt Äußerungen die Runde gemacht, dass es sich bei den Tätern um Flüchtlinge gehandelt haben soll. Dies sei definitiv nicht der Fall, so der Beamte gegenüber EXPRESS.\"',\n",
    "        \"Nicht-Zutreffend\",\n",
    "    ),\n",
    "    (\n",
    "        \"erzähl das Australien, Dänemark, Skandinavien ... 🤦 wenn Deutschland wirklich will kann es. für abgelehnte nur Sachleistungen und Bett wäre ein erster Schritt. die Asylbewerber zahlen würden sich schlagartig halbieren!.\",\n",
    "        \"Anti-Solidarität\",\n",
    "    ),\n",
    "    (\n",
    "        \"Ich hab meinem Rathaus geschrieben, dass ich ein Zimmer für einen oder zwei Flüchtlinge bereitstellen könnte für umsonst. Ka, ob es da richtig ist, aber die werden das wohl weiterleiten.\",\n",
    "        \"Solidarität\",\n",
    "    ),\n",
    "    (\n",
    "        \"Also Venezuela ist richtig arm dran. Meine Frau kommt da her und ich war 3 Wochen über die Feiertage dort. Das kriegt man hier nur nocht richtig mit. Weitaus die meisten Flüchtlinge in der Welt…\",\n",
    "        \"Nicht-Zutreffend\",\n",
    "    ),\n",
    "    (\n",
    "        \"Flüchtlinge aus Ostdeutschland, Preußen und wo se nicht alle herkamen waren schon nicht gern gesehen. Glaube den Deutschen ist egal woher, Hauptsache nicht bei uns\",\n",
    "        \"Nicht-Zutreffend\",\n",
    "    ),\n",
    "    (\"Er hat  Fake Masken an Flüchtlinge gespendet er sollte lieber  in den Knast als hier verteidigt zu werden\", \"Nicht-Zutreffend\"),\n",
    "]\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_06_zero_shot_persona_re1,\n",
    "    few_shot_examples=few_shot_examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 CoT Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (5, 2)\n",
      "┌─────────────────────┬───────┐\n",
      "│ openai_annotation   ┆ count │\n",
      "│ ---                 ┆ ---   │\n",
      "│ str                 ┆ u32   │\n",
      "╞═════════════════════╪═══════╡\n",
      "│ Anti-Solidarität    ┆ 350   │\n",
      "│ Nicht-Zutreffend.   ┆ 313   │\n",
      "│ Nicht-Zutreffend    ┆ 231   │\n",
      "│ Solidarität         ┆ 105   │\n",
      "│ 1. Nicht-Zutreffend ┆ 1     │\n",
      "│ 2. Nicht-Zut…       ┆       │\n",
      "└─────────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ na                ┆ 545   │\n",
      "│ a                 ┆ 350   │\n",
      "│ s                 ┆ 105   │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.1547\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.17      0.88      0.29        68\n",
      "          na       0.92      0.60      0.72       838\n",
      "           s       0.41      0.46      0.43        94\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.50      0.65      0.48      1000\n",
      "weighted avg       0.82      0.60      0.67      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.1973\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.25      0.87      0.39        63\n",
      "          na       0.90      0.55      0.69       389\n",
      "           s       0.46      0.44      0.45        48\n",
      "\n",
      "    accuracy                           0.58       500\n",
      "   macro avg       0.54      0.62      0.51       500\n",
      "weighted avg       0.78      0.58      0.63       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: 0.0615\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.04      1.00      0.07         5\n",
      "          na       0.93      0.64      0.76       449\n",
      "           s       0.37      0.48      0.42        46\n",
      "\n",
      "    accuracy                           0.63       500\n",
      "   macro avg       0.45      0.71      0.42       500\n",
      "weighted avg       0.87      0.63      0.72       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"10 CoT Zero Shot\"\n",
    "prompt_type = \"CHAIN_OF_THOUGHT\"\n",
    "parquet_path = \"datasets/results/10_cot_zero_shot_annotations.parquet\"\n",
    "\n",
    "prompt_10_cot_zero_shot = \"\"\"Sie sind ein wissenschaftlicher Mitarbeiter in einem Forschungsprojekt und haben die Aufgabe, Social-Media-Kommentare zu klassifizieren. Das Forschungsprojekt untersucht die Solidarität gegenüber Flüchtlingen und Geflüchteten in Deutschland. Klassifizieren Sie den gegebenen Social-Media Kommentar zu dem Thema Flüchtlinge, Geflüchtete oder Asyl. Bestimmen Sie dabei, ob der Kommentar Solidarität oder Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten ausdrückt, oder ob er nicht-zutreffend ist und erklären Sie ihre Entscheidung in zwei bis drei Sätzen. Verwenden Sie dafür die folgenden Leitlinien.\n",
    "\n",
    "Leitlinien:\n",
    "Definition von Solidarität:\n",
    "Die Bereitschaft, die eigenen Ressourcen mit anderen zu teilen, sei es direkt, indem man Geld oder Zeit zur Unterstützung anderer spendet, oder indirekt, indem man den Staat dabei unterstützt, einen Teil der durch Steuern oder Beiträge eingenommenen staatlichen Mittel auszugeben und umzuverteilen.\n",
    "\n",
    "Allgemeine Regeln:\n",
    "1.\tBerücksichtigen Sie keine Links (URLs) bei der Klassifizierung.\n",
    "2.\tIronie und Sarkasmus in Kommentaren müssen berücksichtigt werden. \n",
    "\n",
    "Detaillierte Regeln für die Klassifizierung:\n",
    "1.\tEin Kommentar wird mit Solidarität klassifiziert, wenn:\n",
    "a.\tDer Kommentar eindeutig den Willen zur Unterstützung, die Bereitschaft zum Teilen von Ressourcen und/oder zum Leisten von Hilfe zeigt.\n",
    "b.\tDer Kommentar eine positive Einstellung und Dankbarkeit gegenüber denjenigen zeigt, die Ressourcen teilen und/oder helfen.\n",
    "c.\tDer Kommentar die Europäische Union als Solidaritätsunion befürwortet.\n",
    "d.\tDer Kommentar die EU dafür kritisiert, dass sie nicht genug tut, um Ressourcen zu teilen und/oder zu helfen.\n",
    "e.\tDer Kommentar selbst Hilfe leistet, indem er Informationen teilt oder zur Hilfe und Unterstützung aufruft. \n",
    "\n",
    "2.\tEin Kommentar wird mit Anti-Solidarität klassifiziert, wenn:\n",
    "a.\tDer Kommentar eindeutig zeigt, dass kein Wille zur Unterstützung, keine Bereitschaft zum Teilen von Ressourcen und/oder keine Absicht zum Leisten von Hilfe besteht.\n",
    "b.\tDer Kommentar vorschlägt, Flüchtlinge/Geflüchtete von Ressourcen auszuschließen, zu denen sie derzeit Zugang haben.\n",
    "c.\tDer Kommentar Tendenzen zum Nationalismus und zum Schließen von Grenzen zeigt.\n",
    "d.\tDer Kommentar Flüchtlinge/Geflüchtete als schädlich und/oder schlecht für die Gesellschaft betrachtet.\n",
    "\n",
    "3.\tEin Kommentar wird mit Nicht-Zutreffend klassifiziert, wenn:\n",
    "a.\tDer Kommentar nicht eindeutig mit Solidarität oder Anti-Solidarität annotiert werden kann, weil zusätzliche Informationen fehlen.\n",
    "b.\tDer Kommentar keinen Hinweis auf Solidarität oder Anti-Solidarität zeigt.\n",
    "c.\tDer Kommentar andere Themen als Solidarität oder Anti-Solidarität betrifft.\n",
    "d.\tDer Kommentar nicht verständlich ist (enthält z.B. nur Links).\"\"\"\n",
    "\n",
    "prompt_10_cot_zero_shot_final_annotation = (\n",
    "    \"Was ist die finale Annotation? Antworte dieses mal nur mit Solidarität, Anit-Solidarität oder Nicht-Zutreffend.\"\n",
    ")\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_10_cot_zero_shot,\n",
    "    cot_annotation_prompt=prompt_10_cot_zero_shot_final_annotation,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 CoT Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (4, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ Nicht-Zutreffend  ┆ 574   │\n",
      "│ Solidarität       ┆ 216   │\n",
      "│ Anti-Solidarität  ┆ 209   │\n",
      "│ Ambivalent        ┆ 1     │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ a                 ┆ 209   │\n",
      "│ na                ┆ 575   │\n",
      "│ s                 ┆ 216   │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.2356\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.22      0.69      0.34        68\n",
      "          na       0.93      0.64      0.75       838\n",
      "           s       0.32      0.74      0.45        94\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.49      0.69      0.52      1000\n",
      "weighted avg       0.82      0.65      0.70      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.3124\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.35      0.71      0.47        63\n",
      "          na       0.90      0.63      0.74       389\n",
      "           s       0.37      0.77      0.50        48\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.54      0.70      0.57       500\n",
      "weighted avg       0.78      0.65      0.68       500\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: 0.1198\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.03      0.40      0.05         5\n",
      "          na       0.95      0.64      0.77       449\n",
      "           s       0.28      0.72      0.41        46\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.42      0.59      0.41       500\n",
      "weighted avg       0.88      0.65      0.73       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"11 CoT Few Shot\"\n",
    "prompt_type = \"FEW_SHOT_CHAIN_OF_THOUGHT\"\n",
    "parquet_path = \"datasets/results/11_cot_few_shot_annotations.parquet\"\n",
    "\n",
    "cot_few_shot_examples = [\n",
    "    {\n",
    "        \"user\": \"Naja. Klappt in Australien oder Israel ja auch einigermaßen? Und ich denke die Investitionen um Europa abzuschotten dürften geringer sein als das was die Flüchtlinge an Kosten nach sich ziehen,\",\n",
    "        \"assistant\": \"Der Kommentar schlägt vor, die Grenzen der EU zu schließen und keine Flüchtlinge mehr in Deutschland aufzunehmen, um dadurch Kosten zu sparen. Damit zeigt der Kommentar den Willen zum Schließen von Grenzen und dass keine Bereitschaft zum Teilen von Ressourcen oder Leisten von Hilfe besteht. Er ist mit Anti-Solidarität zu annotieren.\",\n",
    "        \"annotation\": \"Anti-Solidarität\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Was soll ich als Privatperson denn tun? Ich kann keine Boote ins Mittelmeer schicken, um die Flüchtlinge zu retten. Das können nur die Politiker und NGOs. Ich empfinde es aber trotzdem als wichtig, dass die Bevölkerung ein Zeichen setzt, dass Flüchtlinge willkommen sind. Auch wenn das Video die Welt nicht ändert, ist es doch besser, als bei den ganzen Hetztaten stumm zu bleiben.\",\n",
    "        \"assistant\": \"Der Kommentar zeigt deutlich, dass der Autor des Kommentars Flüchtlinge in Deutschland willkommen heißen möchte. Dadurch drückt der Kommentar indirekt den Willen zum Teilen von Ressourcen und eindeutig die Bereitschaft zum Leisten von Hilfe aus. Deswegen ist er mit Solidarität zu annotieren.\",\n",
    "        \"annotation\": \"Solidarität\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Die meisten Flüchtlinge kommen aber mit der GFK und nicht mit Artikel 16 GG, der ist hier schlicht nicht relevant, sondern hauptsächlich die GFK, die Grundrechtecharta, die UN-Charta und die europäische Menschenrechtskonvention.\",\n",
    "        \"assistant\": \"Der Kommentar stellt eine Sachlage in Bezug auf Flüchtlinge dar, positioniert sich allerdings nicht dazu. Deswegen zeigt der Kommentar weder Solidarität noch Anti-Solidarität und ist nicht-zutreffend.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Weiß jemand, wie der Anteil von Flüchtlingen ohne Ausweisdokumente vor 2015 war?\",\n",
    "        \"assistant\": \"Der Kommentar stellt eine sachliche Frage in Bezug auf Flüchtlinge. Es gibt weder Hinweise auf Solidarität noch Anti-Solidarität, deswegen ist der Kommentar nicht zutreffend.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": '\"In sozialen Netzwerken hatten zuletzt Äußerungen die Runde gemacht, dass es sich bei den Tätern um Flüchtlinge gehandelt haben soll. Dies sei definitiv nicht der Fall, so der Beamte gegenüber EXPRESS.\"',\n",
    "        \"assistant\": \"Der Kommentar ist in Anführungsstrichen geschrieben, was darauf hinweist, dass er jemanden oder etwas anderes zitiert und keine eigene Meinung ausdrückt. Zusätzlich stellt der Kommentar lediglich eine Sachlage dar, ohne sich dazu zu positionieren. Deswegen ist der Kommentar nicht-zutreffend.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"erzähl das Australien, Dänemark, Skandinavien ... 🤦 wenn Deutschland wirklich will kann es. für abgelehnte nur Sachleistungen und Bett wäre ein erster Schritt. die Asylbewerber zahlen würden sich schlagartig halbieren!.\",\n",
    "        \"assistant\": \"Der Kommentar schlägt vor, Asylbewerber, welche auch geflüchtete Menschen sind, von Ressourcen auszuschließen, welche ihnen aktuell noch zur Verfügung stehen, um dafür zu sorgen, dass weniger Flüchtlinge nach Deutschland kommen. Damit zeigt der Kommentar eindeutig, dass keine Bereitschaft zum Teilen von Ressourcen oder Leisten von Hilfe besteht und mit Anti-Solidarität zu annotieren ist.\",\n",
    "        \"annotation\": \"Anti-Solidarität\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Ich hab meinem Rathaus geschrieben, dass ich ein Zimmer für einen oder zwei Flüchtlinge bereitstellen könnte für umsonst. Ka, ob es da richtig ist, aber die werden das wohl weiterleiten.\",\n",
    "        \"assistant\": \"Der Kommentar zeigt, dass der Autor des Kommentars bereit ist, Flüchtlinge bei sich aufzunehmen und ihnen damit zu helfen. Damit drückt er eindeutig den Willen zum Leisten von Hilfe aus und ist mit Solidarität zu annotieren.\",\n",
    "        \"annotation\": \"Solidarität\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Also Venezuela ist richtig arm dran. Meine Frau kommt da her und ich war 3 Wochen über die Feiertage dort. Das kriegt man hier nur nocht richtig mit. Weitaus die meisten Flüchtlinge in der Welt…\",\n",
    "        \"assistant\": \"Der Kommentar ist nicht eindeutig zu verstehen und es kann weder Solidarität noch Anti-Solidarität festgestellt werden. Deswegen ist der Kommentar nicht-zutreffend.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Flüchtlinge aus Ostdeutschland, Preußen und wo se nicht alle herkamen waren schon nicht gern gesehen. Glaube den Deutschen ist egal woher, Hauptsache nicht bei uns\",\n",
    "        \"assistant\": \"Der Kommentar stellt eine Vermutung darüber an, wie Deutsche im Allgemeinen zu Flüchtlingen stehen, positioniert sich selbst allerdings nicht dazu. Deswegen zeigt der Kommentar weder Solidarität noch Anti-Solidarität und ist nicht-zutreffend.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Er hat  Fake Masken an Flüchtlinge gespendet er sollte lieber  in den Knast als hier verteidigt zu werden\",\n",
    "        \"assistant\": \"Der Kommentar äußert sich zu jemandem, der ohne weiteren Kontext nicht näher bestimmt werden kann. Er zeigt weder Anzeichen für Solidarität noch Anti-Solidarität und ist deswegen nicht-zutreffend.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "]\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_10_cot_zero_shot,\n",
    "    cot_annotation_prompt=prompt_10_cot_zero_shot_final_annotation,\n",
    "    few_shot_examples=cot_few_shot_examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 CoT Few Shot Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROMPT EVAL RUN] Für alle Kommentare wurden bereits Annotationen erstellt.\n",
      "\n",
      "[PIPELINE] Nicht umgewandelte OpenAI Model Annotationen:  shape: (4, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ Anti-Solidarität  ┆ 401   │\n",
      "│ Nicht-Zutreffend  ┆ 399   │\n",
      "│ Solidarität       ┆ 199   │\n",
      "│ Ambivalent        ┆ 1     │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Umgewandelte OpenAI Model Annotationen:  shape: (3, 2)\n",
      "┌───────────────────┬───────┐\n",
      "│ openai_annotation ┆ count │\n",
      "│ ---               ┆ ---   │\n",
      "│ str               ┆ u32   │\n",
      "╞═══════════════════╪═══════╡\n",
      "│ na                ┆ 400   │\n",
      "│ a                 ┆ 401   │\n",
      "│ s                 ┆ 199   │\n",
      "└───────────────────┴───────┘\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha: 0.0918\n",
      "\n",
      "[PIPELINE] Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.16      0.94      0.27        68\n",
      "          na       0.95      0.45      0.62       838\n",
      "           s       0.32      0.68      0.44        94\n",
      "\n",
      "    accuracy                           0.51      1000\n",
      "   macro avg       0.48      0.69      0.44      1000\n",
      "weighted avg       0.84      0.51      0.58      1000\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2015: 0.1695\n",
      "\n",
      "[PIPELINE] Classification Report 2015:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.26      0.94      0.40        63\n",
      "          na       0.96      0.44      0.61       389\n",
      "           s       0.35      0.65      0.46        48\n",
      "\n",
      "    accuracy                           0.53       500\n",
      "   macro avg       0.52      0.68      0.49       500\n",
      "weighted avg       0.81      0.53      0.57       500\n",
      "\n",
      "\n",
      "[PIPELINE] Krippendorf's Alpha 2022: -0.018\n",
      "\n",
      "[PIPELINE] Classification Report 2022:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       0.03      1.00      0.06         5\n",
      "          na       0.95      0.46      0.62       449\n",
      "           s       0.30      0.72      0.42        46\n",
      "\n",
      "    accuracy                           0.49       500\n",
      "   macro avg       0.43      0.73      0.37       500\n",
      "weighted avg       0.88      0.49      0.60       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_name = \"12 CoT Few Shot Model\"\n",
    "prompt_type = \"FEW_SHOT_CHAIN_OF_THOUGHT\"\n",
    "parquet_path = \"datasets/results/12_cot_few_shot_model_annotations.parquet\"\n",
    "\n",
    "cot_few_shot_examples = [\n",
    "    {\n",
    "        \"user\": \"Naja. Klappt in Australien oder Israel ja auch einigermaßen? Und ich denke die Investitionen um Europa abzuschotten dürften geringer sein als das was die Flüchtlinge an Kosten nach sich ziehen,\",\n",
    "        \"assistant\": \"Der Kommentar drückt Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten aus, da er vorschlägt, sie von Ressourcen auszuschließen und die Kosten, die mit ihnen verbunden sind, als negativ darstellt.\",\n",
    "        \"annotation\": \"Anti-Solidarität\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Was soll ich als Privatperson denn tun? Ich kann keine Boote ins Mittelmeer schicken, um die Flüchtlinge zu retten. Das können nur die Politiker und NGOs. Ich empfinde es aber trotzdem als wichtig, dass die Bevölkerung ein Zeichen setzt, dass Flüchtlinge willkommen sind. Auch wenn das Video die Welt nicht ändert, ist es doch besser, als bei den ganzen Hetztaten stumm zu bleiben.\",\n",
    "        \"assistant\": \"Der Kommentar drückt Solidarität gegenüber Flüchtlingen und Geflüchteten aus, da er den Willen zur Unterstützung und die Bereitschaft zum Zeigen von Solidarität betont, auch wenn die Person selbst keine direkten Maßnahmen ergreifen kann.\",\n",
    "        \"annotation\": \"Solidarität\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Die meisten Flüchtlinge kommen aber mit der GFK und nicht mit Artikel 16 GG, der ist hier schlicht nicht relevant, sondern hauptsächlich die GFK, die Grundrechtecharta, die UN-Charta und die europäische Menschenrechtskonvention.\",\n",
    "        \"assistant\": \"Nicht zutreffend. Der Kommentar bezieht sich nicht auf Solidarität oder Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten, sondern auf die rechtlichen Grundlagen, die für sie gelten.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Weiß jemand, wie der Anteil von Flüchtlingen ohne Ausweisdokumente vor 2015 war?\",\n",
    "        \"assistant\": \"Nicht-Zutreffend. Der Kommentar stellt eine Frage zur Statistik über Flüchtlinge ohne Ausweisdokumente vor 2015 und enthält keine Hinweise auf Solidarität oder Anti-Solidarität.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": '\"In sozialen Netzwerken hatten zuletzt Äußerungen die Runde gemacht, dass es sich bei den Tätern um Flüchtlinge gehandelt haben soll. Dies sei definitiv nicht der Fall, so der Beamte gegenüber EXPRESS.\"',\n",
    "        \"assistant\": \"Der gegebene Kommentar kann nicht eindeutig mit Solidarität oder Anti-Solidarität annotiert werden, da er keine klare Position zu Solidarität oder Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten ausdrückt.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"erzähl das Australien, Dänemark, Skandinavien ... 🤦 wenn Deutschland wirklich will kann es. für abgelehnte nur Sachleistungen und Bett wäre ein erster Schritt. die Asylbewerber zahlen würden sich schlagartig halbieren!.\",\n",
    "        \"assistant\": \"Der Kommentar drückt Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten aus, da er vorschlägt, sie von Ressourcen auszuschließen und sie als finanzielle Belastung für die Gesellschaft betrachtet.\",\n",
    "        \"annotation\": \"Anti-Solidarität\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Ich hab meinem Rathaus geschrieben, dass ich ein Zimmer für einen oder zwei Flüchtlinge bereitstellen könnte für umsonst. Ka, ob es da richtig ist, aber die werden das wohl weiterleiten.\",\n",
    "        \"assistant\": \"Der Kommentar drückt Solidarität gegenüber Flüchtlingen aus, da der Autor bereit ist, seine Ressourcen zu teilen und Hilfe anzubieten.\",\n",
    "        \"annotation\": \"Solidarität\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Also Venezuela ist richtig arm dran. Meine Frau kommt da her und ich war 3 Wochen über die Feiertage dort. Das kriegt man hier nur nocht richtig mit. Weitaus die meisten Flüchtlinge in der Welt…\",\n",
    "        \"assistant\": \"Nicht-Zutreffend. Der Kommentar bezieht sich auf die Situation in Venezuela und erwähnt Flüchtlinge, gibt jedoch keine klare Aussage zur Solidarität oder Anti-Solidarität gegenüber ihnen.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Flüchtlinge aus Ostdeutschland, Preußen und wo se nicht alle herkamen waren schon nicht gern gesehen. Glaube den Deutschen ist egal woher, Hauptsache nicht bei uns\",\n",
    "        \"assistant\": \"Anti-Solidarität: Der Kommentar zeigt eine ablehnende Haltung gegenüber Flüchtlingen und Geflüchteten und drückt aus, dass es den Deutschen egal ist, woher sie kommen, solange sie nicht in Deutschland sind.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Er hat  Fake Masken an Flüchtlinge gespendet er sollte lieber  in den Knast als hier verteidigt zu werden\",\n",
    "        \"assistant\": \"Nicht zutreffend. Der Kommentar äußert sich kritisch über jemanden, der gefälschte Masken an Flüchtlinge gespendet hat, und fordert Konsequenzen. Es wird jedoch keine klare Position zur Solidarität oder Anti-Solidarität gegenüber Flüchtlingen und Geflüchteten eingenommen.\",\n",
    "        \"annotation\": \"Nicht-Zutreffend\",\n",
    "    },\n",
    "]\n",
    "\n",
    "metrics_results[prompt_name] = prompt_pipeline(\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_type=prompt_type,\n",
    "    eval_results_parquet_path=parquet_path,\n",
    "    annotated_comments_df=annotated_comments_df,\n",
    "    system_prompt=prompt_10_cot_zero_shot,\n",
    "    cot_annotation_prompt=prompt_10_cot_zero_shot_final_annotation,\n",
    "    few_shot_examples=cot_few_shot_examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro f1-score</th>\n",
       "      <th>kripps_alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01 First Try</th>\n",
       "      <td>0.723</td>\n",
       "      <td>0.386563</td>\n",
       "      <td>0.0524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02 Zero Shot Prompt</th>\n",
       "      <td>0.543</td>\n",
       "      <td>0.452561</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03 Zero Shot Prompt Re1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450146</td>\n",
       "      <td>0.1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04 Zero Shot Prompt Re2</th>\n",
       "      <td>0.541</td>\n",
       "      <td>0.452150</td>\n",
       "      <td>0.0813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05 Zero Shot Persona</th>\n",
       "      <td>0.605</td>\n",
       "      <td>0.488170</td>\n",
       "      <td>0.1687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06 Zero Shot Persona Re1</th>\n",
       "      <td>0.641</td>\n",
       "      <td>0.503602</td>\n",
       "      <td>0.2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07 One Shot</th>\n",
       "      <td>0.419</td>\n",
       "      <td>0.389255</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08 Few Shot Demo 3</th>\n",
       "      <td>0.589</td>\n",
       "      <td>0.484128</td>\n",
       "      <td>0.1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09 Few Shot Demo 10</th>\n",
       "      <td>0.519</td>\n",
       "      <td>0.442915</td>\n",
       "      <td>0.1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 CoT Zero Shot</th>\n",
       "      <td>0.604</td>\n",
       "      <td>0.481251</td>\n",
       "      <td>0.1547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11 CoT Few Shot</th>\n",
       "      <td>0.650</td>\n",
       "      <td>0.515129</td>\n",
       "      <td>0.2356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 CoT Few Shot Model</th>\n",
       "      <td>0.509</td>\n",
       "      <td>0.441763</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  macro f1-score  kripps_alpha\n",
       "prompt                                                          \n",
       "01 First Try                 0.723        0.386563        0.0524\n",
       "02 Zero Shot Prompt          0.543        0.452561        0.0856\n",
       "03 Zero Shot Prompt Re1      0.585        0.450146        0.1169\n",
       "04 Zero Shot Prompt Re2      0.541        0.452150        0.0813\n",
       "05 Zero Shot Persona         0.605        0.488170        0.1687\n",
       "06 Zero Shot Persona Re1     0.641        0.503602        0.2021\n",
       "07 One Shot                  0.419        0.389255        0.0065\n",
       "08 Few Shot Demo 3           0.589        0.484128        0.1762\n",
       "09 Few Shot Demo 10          0.519        0.442915        0.1112\n",
       "10 CoT Zero Shot             0.604        0.481251        0.1547\n",
       "11 CoT Few Shot              0.650        0.515129        0.2356\n",
       "12 CoT Few Shot Model        0.509        0.441763        0.0918"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_results_pdf = pl.from_dicts(list(metrics_results.values())).to_pandas().set_index(\"prompt\")\n",
    "metrics_results_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=accuracy<br>prompt=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "accuracy",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "accuracy",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "01 First Try",
          "02 Zero Shot Prompt",
          "03 Zero Shot Prompt Re1",
          "04 Zero Shot Prompt Re2",
          "05 Zero Shot Persona",
          "06 Zero Shot Persona Re1",
          "07 One Shot",
          "08 Few Shot Demo 3",
          "09 Few Shot Demo 10",
          "10 CoT Zero Shot",
          "11 CoT Few Shot",
          "12 CoT Few Shot Model"
         ],
         "xaxis": "x",
         "y": [
          0.723,
          0.543,
          0.585,
          0.541,
          0.605,
          0.641,
          0.419,
          0.589,
          0.519,
          0.604,
          0.65,
          0.509
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=macro f1-score<br>prompt=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "macro f1-score",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "macro f1-score",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "01 First Try",
          "02 Zero Shot Prompt",
          "03 Zero Shot Prompt Re1",
          "04 Zero Shot Prompt Re2",
          "05 Zero Shot Persona",
          "06 Zero Shot Persona Re1",
          "07 One Shot",
          "08 Few Shot Demo 3",
          "09 Few Shot Demo 10",
          "10 CoT Zero Shot",
          "11 CoT Few Shot",
          "12 CoT Few Shot Model"
         ],
         "xaxis": "x",
         "y": [
          0.38656265719139055,
          0.45256052291516696,
          0.450145744218265,
          0.4521496223606043,
          0.48816975997139433,
          0.5036021840497037,
          0.38925509950123854,
          0.4841280480486674,
          0.44291523554544004,
          0.48125135810623415,
          0.5151287655843869,
          0.4417633541000863
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=kripps_alpha<br>prompt=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "kripps_alpha",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "kripps_alpha",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "01 First Try",
          "02 Zero Shot Prompt",
          "03 Zero Shot Prompt Re1",
          "04 Zero Shot Prompt Re2",
          "05 Zero Shot Persona",
          "06 Zero Shot Persona Re1",
          "07 One Shot",
          "08 Few Shot Demo 3",
          "09 Few Shot Demo 10",
          "10 CoT Zero Shot",
          "11 CoT Few Shot",
          "12 CoT Few Shot Model"
         ],
         "xaxis": "x",
         "y": [
          0.0524,
          0.0856,
          0.1169,
          0.0813,
          0.1687,
          0.2021,
          0.0065,
          0.1762,
          0.1112,
          0.1547,
          0.2356,
          0.0918
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "prompt"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.line(metrics_results_pdf, width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ergebnisse über 5 Pipeline Runs - 06 Zero Shot Persona Re1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro f1-score</th>\n",
       "      <th>kripps_alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>06 Zero Shot Persona Re1 v0</th>\n",
       "      <td>0.641</td>\n",
       "      <td>0.503602</td>\n",
       "      <td>0.2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06 Zero Shot Persona Re1 v1</th>\n",
       "      <td>0.644</td>\n",
       "      <td>0.511115</td>\n",
       "      <td>0.2117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06 Zero Shot Persona Re1 v2</th>\n",
       "      <td>0.647</td>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06 Zero Shot Persona Re1 v3</th>\n",
       "      <td>0.642</td>\n",
       "      <td>0.510884</td>\n",
       "      <td>0.2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06 Zero Shot Persona Re1 v4</th>\n",
       "      <td>0.638</td>\n",
       "      <td>0.500039</td>\n",
       "      <td>0.1939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy  macro f1-score  kripps_alpha\n",
       "prompt                                                             \n",
       "06 Zero Shot Persona Re1 v0     0.641        0.503602        0.2021\n",
       "06 Zero Shot Persona Re1 v1     0.644        0.511115        0.2117\n",
       "06 Zero Shot Persona Re1 v2     0.647        0.505998        0.2066\n",
       "06 Zero Shot Persona Re1 v3     0.642        0.510884        0.2066\n",
       "06 Zero Shot Persona Re1 v4     0.638        0.500039        0.1939"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Für jeden Prompt-Evaluation Durchlauf möchte ich nur die Ergebnisse abspeichern, aber nicht ausgeben. Deshalb\n",
    "# deaktiviere ich für die Prompt-Evaluation Durchläufe die \"print\" Funktion.\n",
    "# vgl. Stackoverflow: https://stackoverflow.com/a/45669280/10050559\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "\n",
    "persona_re1_pipeline_runs = [\n",
    "    {\"name\": \"06 Zero Shot Persona Re1 v0\", \"path\": \"datasets/results/06_zero_shot_persona_re1_annotations.parquet\"},\n",
    "    {\"name\": \"06 Zero Shot Persona Re1 v1\", \"path\": \"datasets/results/06_zero_shot_persona_re1_annotations.v01.parquet\"},\n",
    "    {\"name\": \"06 Zero Shot Persona Re1 v2\", \"path\": \"datasets/results/06_zero_shot_persona_re1_annotations.v02.parquet\"},\n",
    "    {\"name\": \"06 Zero Shot Persona Re1 v3\", \"path\": \"datasets/results/06_zero_shot_persona_re1_annotations.v03.parquet\"},\n",
    "    {\"name\": \"06 Zero Shot Persona Re1 v4\", \"path\": \"datasets/results/06_zero_shot_persona_re1_annotations.v04.parquet\"},\n",
    "]\n",
    "\n",
    "metrics_results_06_zero_shot_persona_re1 = {}\n",
    "\n",
    "for pipeline_run in persona_re1_pipeline_runs:\n",
    "    run_name = pipeline_run[\"name\"]\n",
    "    run_path = pipeline_run[\"path\"]\n",
    "\n",
    "    with HiddenPrints():\n",
    "        metrics_results_06_zero_shot_persona_re1[run_name] = prompt_pipeline(\n",
    "            prompt_name=run_name,\n",
    "            prompt_type=\"ZERO_SHOT\",\n",
    "            eval_results_parquet_path=run_path,\n",
    "            annotated_comments_df=annotated_comments_df,\n",
    "            system_prompt=prompt_06_zero_shot_persona_re1,\n",
    "        )\n",
    "\n",
    "metrics_results_pdf = pl.from_dicts(list(metrics_results_06_zero_shot_persona_re1.values())).to_pandas().set_index(\"prompt\")\n",
    "metrics_results_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=accuracy<br>prompt=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "accuracy",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "accuracy",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "06 Zero Shot Persona Re1 v0",
          "06 Zero Shot Persona Re1 v1",
          "06 Zero Shot Persona Re1 v2",
          "06 Zero Shot Persona Re1 v3",
          "06 Zero Shot Persona Re1 v4"
         ],
         "xaxis": "x",
         "y": [
          0.641,
          0.644,
          0.647,
          0.642,
          0.638
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=macro f1-score<br>prompt=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "macro f1-score",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "macro f1-score",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "06 Zero Shot Persona Re1 v0",
          "06 Zero Shot Persona Re1 v1",
          "06 Zero Shot Persona Re1 v2",
          "06 Zero Shot Persona Re1 v3",
          "06 Zero Shot Persona Re1 v4"
         ],
         "xaxis": "x",
         "y": [
          0.5036021840497037,
          0.5111150961652481,
          0.5059983172230266,
          0.5108841067463588,
          0.5000392279166458
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=kripps_alpha<br>prompt=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "kripps_alpha",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "kripps_alpha",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "06 Zero Shot Persona Re1 v0",
          "06 Zero Shot Persona Re1 v1",
          "06 Zero Shot Persona Re1 v2",
          "06 Zero Shot Persona Re1 v3",
          "06 Zero Shot Persona Re1 v4"
         ],
         "xaxis": "x",
         "y": [
          0.2021,
          0.2117,
          0.2066,
          0.2066,
          0.1939
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "prompt"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.line(metrics_results_pdf, width=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba-sentiment-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
